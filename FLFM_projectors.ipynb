{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLFM Forward and Backward Projector Generator\n",
    "__Requirements__\n",
    "- Dependencies\n",
    "    - OpenCV, Numpy, Torch, Matplotlib, gc\n",
    "- Required Information\n",
    "    - Camera related information\n",
    "    - A image of the lenslets (or a image that shows the outlines.)\n",
    "    \n",
    "__Warning__\n",
    "- The methods used in the following code may generate inaccruate results. Consider using experimentally measured PSFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Camera Information\n",
    "(In the future, this will be done by reading a .txt or a .csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up Specific Constants\n",
    "NA = 0.4\n",
    "fobj = 10000\n",
    "f1 = 1\n",
    "f2 = 1\n",
    "fm = np.array([47000])\n",
    "\n",
    "mla2sensor = 47000 # microns\n",
    "lenspitch = 2520 # Lens pitch in microns \n",
    "pixel_size = 3.54 # Also referred to as pixel pitch in microns/px\n",
    "refractive_index = 1 # Refractive index of the medium\n",
    "wavelength = 0.5530\n",
    "\n",
    "noLensHoriz = 3\n",
    "noLensVert = 3\n",
    "\n",
    "spacingPixels = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLFM_setCameraParams(config):\n",
    "    # Config should be an array with the following parameters:\n",
    "    # [NA, fobj, f1, f2, fm, mla2sensor, lenspitch, pixel_size, wavelength, refractive_index, noLensHoriz, noLensVert, spacingPixels, horizOffset, vertOffset, shiftRow, gridRot]\n",
    "    \n",
    "    objRad = config[0] * config[1] # Objective radius = NA * fobj\n",
    "    k = 2 * np.pi * config[9] / config[8] # k = 2 * pi * refractive_index / wavelength (wave number)\n",
    "    M = (config[4] * config[3]) / (config[2] * config[1]) # Magnification = fm * f2 / (f1 * fobj)\n",
    "    d_refract = 3.5e-3 # Index of Refraction (__Don't know wherer the number came from__)\n",
    "    fsRad = config[6] * config[3] / (2 * config[4]) # Field stop radius = lenspitch * f2 / (2 * fm)\n",
    "    fovRad = fsRad / config[2]\n",
    "    return [objRad, k, M, d_refract, fsRad, fovRad]\n",
    "\n",
    "# Example: camera_params = FLFM_setCameraParams(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolution(camera_params, depth_step):\n",
    "    # Find the number of pixels behind a lesnlet\n",
    "    lenslet_pixels = [len(perspectives[0,0,0,:]), len(perspectives[0,0,:,0])]\n",
    "    # Corresponding sensor resolution\n",
    "    sensor_res = pixel_size\n",
    "    object_res = [pixel_size/camera_params[2], pixel_size/camera_params[2], depth_step] # config[2] is the magnification\n",
    "    fovRadVox = (camera_params[5] / i for i in object_res)  # Field of view radius in voxels\n",
    "    return [lenslet_pixels, sensor_res, object_res, fovRadVox]\n",
    "\n",
    "# example: res = resolution(camera_params, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hough Transform for Circle Detection \n",
    "(Do not need to do everytime unless mask has changed for some ungodly reason.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img = cv.imread(r'./test_images/mask1.tif', cv.IMREAD_GRAYSCALE)\n",
    "min_radius = int(len(mask_img[0,:])/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Hough circle detection, rounded to the nearest integer/pixel\n",
    "circles = cv.HoughCircles(mask_img, cv.HOUGH_GRADIENT, 1.2, 1.5*min_radius, param1=70,param2=25, minRadius= min_radius,maxRadius=3*min_radius)\n",
    "circles = np.uint16(np.around(circles))\n",
    "circles = np.reshape(circles, (circles.shape[1], circles.shape[2]))\n",
    "\n",
    "# Find which one is the center circle\n",
    "circle_x_avg = np.mean(circles[:,0])\n",
    "circle_y_avg = np.mean(circles[:,1])\n",
    "circle_r_avg = np.mean(circles[:,2])\n",
    "\n",
    "distances = []\n",
    "theta = []\n",
    "\n",
    "for i in range(len(circles[:,0])):\n",
    "    x,y = circles[i,0]-circle_x_avg, circles[i,1]-circle_y_avg\n",
    "    distances.append(np.sqrt((circles[i,0]-circle_x_avg)**2 + (circles[i,1]-circle_y_avg)**2))\n",
    "    theta.append(np.arctan2(y,x))\n",
    "\n",
    "theta = np.delete(theta, np.argmin(distances)) # Remove the center circle\n",
    "distances = np.delete(distances, np.argmin(distances)) # Remove the center circle\n",
    "\n",
    "theta = np.sort(theta) # Sort the angles\n",
    "  \n",
    "circle_theta_avg = np.mean(theta) # Average angle between circles\n",
    "circle_theta_avg2 = (np.argmax(theta) - np.argmin(theta)) / (len(theta) - 1) #\n",
    "circle_dist_avg = np.mean(distances)\n",
    "\n",
    "circles_corrected = np.array([circle_x_avg, circle_y_avg, circle_r_avg])\n",
    "\n",
    "for i in range(len(theta)):\n",
    "    circles_corrected = np.vstack((circles_corrected, (circle_x_avg+circle_dist_avg*np.cos(theta[i]), circle_y_avg+circle_dist_avg*np.sin(theta[i]), circle_r_avg))) # new circle centers and radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_lenslet = int(0) # center circle index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenslet_distances_og = np.zeros((len(circles_corrected[:,0]), len(circles_corrected[:,0])))\n",
    "lenslet_angles = np.zeros((len(circles_corrected[:,0]), len(circles_corrected[:,0])))\n",
    "\n",
    "# Find the distances between the lenset centers\n",
    "for i in range(len(circles_corrected[:,0])):\n",
    "    for j in range(len(circles_corrected[:,0])):\n",
    "        lenslet_distances_og[i,j] = (np.sqrt((circles_corrected[i,0]-circles_corrected[j,0])**2 + (circles_corrected[i,1]-circles_corrected[j,1])**2))\n",
    "        lenslet_angles[i,j] = np.arctan2(circles_corrected[i,1]-circles_corrected[j,1], circles_corrected[i,0]-circles_corrected[j,0])\n",
    "\n",
    "# Grab the 2nd diagonal of the matrix\n",
    "lenslet_distances = np.diagonal(lenslet_distances_og, offset = 1)\n",
    "lenslet_angles = np.diagonal(lenslet_angles, offset = 1)\n",
    "lenslet_distance_avg = np.mean(lenslet_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenslet_circle_mask = np.zeros((int(2*circles_corrected[0,2]+1),int(2*circles_corrected[0,2]+1)))\n",
    "\n",
    "# Create a circular mask that has 0s outside the circle and 1s inside the circle\n",
    "for i in range(int(2*circles_corrected[0,2]+1)):\n",
    "    r = circles_corrected[0,2]\n",
    "    for j in range(int(2*circles_corrected[0,2]+1)):\n",
    "        \n",
    "        if np.sqrt((i-r)**2 + (j-r)**2) <= r: # Assuming the radius of the first circle is the same as the rest\n",
    "            lenslet_circle_mask[i,j] = 1\n",
    "        else:\n",
    "            lenslet_circle_mask[i,j] = 0\n",
    "\n",
    "mask_tensor = torch.from_numpy(lenslet_circle_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspectives = torch.zeros(int(len(frames)), int(len(circles_corrected[:,0])) , int(2*circles_corrected[0,2]+1), int(2*circles_corrected[0,2]+1)) # Making the different perspectives te \"channels\", also the frames are always odd numbers\n",
    "# The first dimension is the frame number, the second dimension is the lenslet number, the third and fourth dimensions are the x and y dimensions of the lenslet\n",
    "\n",
    "for i in range(len(frames)):\n",
    "    for j in range(len(circles_corrected[:,0])):\n",
    "        placeholder = torch.Tensor(frames[i][int(circles_corrected[j,1]-circles_corrected[j,2]):int(circles_corrected[j,1]+circles_corrected[j,2]), int(circles_corrected[j,0]-circles_corrected[j,2]):int(circles_corrected[j,0]+circles_corrected[j,2])]) # Don't know why x and y are switched\n",
    "        \n",
    "        if placeholder.shape == perspectives[0,0,:,:].shape:\n",
    "            placeholder[:,:] = torch.mul(placeholder, mask_tensor)\n",
    "            perspectives[i,j,:,:] = placeholder[:,:]\n",
    "            \n",
    "        else:\n",
    "            # If the circle is too close to the edge of the image, we need to pad it\n",
    "            placeholder_x_deficit = int(2*circles_corrected[j,2]+1) - placeholder.shape[0]\n",
    "            placeholder_y_deficit = int(2*circles_corrected[j,2]+1) - placeholder.shape[1]\n",
    "            \n",
    "            if placeholder_x_deficit > 0:\n",
    "                placeholder = torch.cat((placeholder, torch.zeros(placeholder_x_deficit, placeholder.shape[1])), 0)\n",
    "            if placeholder_y_deficit > 0:\n",
    "                placeholder = torch.cat((placeholder, torch.zeros(placeholder.shape[0], placeholder_y_deficit)), 1)\n",
    "            if placeholder_x_deficit < 0:\n",
    "                placeholder = torch.cat((placeholder, torch.zeros(placeholder_x_deficit, placeholder.shape[1])), 0)\n",
    "            if placeholder_y_deficit < 0:\n",
    "                placeholder = torch.cat((placeholder, torch.zeros(placeholder.shape[0], placeholder_y_deficit)), 1)\n",
    "                \n",
    "            placeholder[:,:] = torch.mul(placeholder, mask_tensor)\n",
    "            perspectives[i,j,:,:] = placeholder[:,:] # This is the same as the placeholder, but padded with zeros if the circle is too close to the edge of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up Specific Constants\n",
    "grid_Type = \"hex\"\n",
    "\n",
    "NA = 0.4\n",
    "fobj = 10000\n",
    "f1 = 1\n",
    "f2 = 1\n",
    "fm = np.array([47000])\n",
    "\n",
    "mla2sensor = 47000 # microns\n",
    "lenspitch = 2520 # Lens pitch in microns \n",
    "pixel_size = 3.54 # Also referred to as pixel pitch in microns/px\n",
    "refractive_index = 1 # Refractive index of the medium\n",
    "wavelength = 0.5530\n",
    "\n",
    "noLensHoriz = 3\n",
    "noLensVert = 3\n",
    "\n",
    "spacingPixels = 777\n",
    "horizOffset = 1269\n",
    "vertOffset = 690\n",
    "\n",
    "shiftRow = 0\n",
    "gridRot = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLFM_setCameraParams(config):\n",
    "    # Config should be an array with the following parameters:\n",
    "    # [NA, fobj, f1, f2, fm, mla2sensor, lenspitch, pixel_size, wavelength, refractive_index, noLensHoriz, noLensVert, spacingPixels, horizOffset, vertOffset, shiftRow, gridRot]\n",
    "    \n",
    "    objRad = config[0] * config[1] # Objective radius = NA * fobj\n",
    "    k = 2 * np.pi * config[9] / config[8] # k = 2 * pi * refractive_index / wavelength (wave number)\n",
    "    M = (config[4] * config[3]) / (config[2] * config[1]) # Magnification = fm * f2 / (f1 * fobj)\n",
    "    d_refract = 3.5e-3 # Index of Refraction (__Don't know wherer the number came from__)\n",
    "    fsRad = config[6] * config[3] / (2 * config[4]) # Field stop radius = lenspitch * f2 / (2 * fm)\n",
    "    fovRad = fsRad / config[2]\n",
    "    return [objRad, k, M, d_refract, fsRad, fovRad]\n",
    "\n",
    "# Example: camera_params = FLFM_setCameraParams(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolution(camera_params, depth_step):\n",
    "    # Find the number of pixels behind a lesnlet\n",
    "    lenslet_pixels = [len(perspectives[0,0,0,:]), len(perspectives[0,0,:,0])]\n",
    "    # Corresponding sensor resolution\n",
    "    sensor_res = pixel_size\n",
    "    object_res = [pixel_size/camera_params[2], pixel_size/camera_params[2], depth_step] # config[2] is the magnification\n",
    "    fovRadVox = (camera_params[5] / i for i in object_res)  # Field of view radius in voxels\n",
    "    return [lenslet_pixels, sensor_res, object_res, fovRadVox]\n",
    "\n",
    "# example: res = resolution(camera_params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(perspectives, './models_DONOTCOMMIT/perspectives.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_params = FLFM_setCameraParams([NA, fobj, f1, f2, fm, mla2sensor, lenspitch, pixel_size, wavelength, refractive_index, noLensHoriz, noLensVert, spacingPixels, horizOffset, vertOffset, shiftRow, gridRot])\n",
    "res = resolution(camera_params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transmittance(wavenumber, lenslet_centers, calibration_img, focal_lengths, pixel_pitch):\n",
    "    # Defining the local lenslet space\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    lenslet_pixels = 2*round(lenslet_centers[0,2])\n",
    "    \n",
    "    lenslet_pitch = pixel_pitch * lenslet_pixels # Supposedly the lenslet pitch is 2x the radius of the lenslet\n",
    "    \n",
    "    NNum_half = (lenslet_pixels / 2) # Number of pixels in the numerator, assuming the lenslet is square\n",
    "    xML = pixel_pitch * torch.arange(start=-NNum_half+1, end=NNum_half-1, step = 1, dtype = torch.float32) # x coordinates of the lenslet space\n",
    "    yML = xML.clone() # y coordinates of the lenslet space in the same units as xML\n",
    "    \n",
    "    #ulens_transmittance = np.zeros((len(focal_lengths),len(xML),len(yML)), dtype = np.complex64) # [focal length, x, y]\n",
    "    ulens_transmittance = torch.zeros([len(focal_lengths),len(xML),len(yML)], dtype = torch.complex64) # [focal length, x, y]\n",
    "    # Indexing: [lenslet x, lenslet y, focal length]\n",
    "    # Lenslet centers is saved as [lens no, [x,y,r]]\n",
    "    # We already have the distances between the lenslets, so we need to find the correct index for the x norm and y norm\n",
    "\n",
    "    distance = (torch.pow(xML.tile((len(xML),1)),2) + torch.pow(yML.reshape(-1,1).tile((1,len(yML))),2))\n",
    "    #distance = distance.numpy()\n",
    "\n",
    "\n",
    "    condition = (distance < (lenslet_pitch/2)**2) # Condition for the lenslet transmittance, is 1 inside the lenslet and 0 outside the lenslet\n",
    "    #condition.dtype\n",
    "    condition = condition.to(torch.complex64)\n",
    "    distance = distance.to(torch.complex64)\n",
    "    #print(distance_squared)\n",
    "    \n",
    "    exp_workaround = (-0.5 * distance * wavenumber / focal_lengths[0]).to(torch.complex64)\n",
    "    mul_test = torch.mul(torch.tensor(1j)*torch.sin(exp_workaround) + torch.cos(exp_workaround), condition)\n",
    "    #print(torch.angle(torch.tensor(1j)*torch.sin(exp_workaround) + torch.cos(exp_workaround)))\n",
    "\n",
    "    #exp_workaround = np.multiply(-0.5j * wavenumber / focal_lengths[0] , distance).astype(np.complex64)\n",
    "    \n",
    "    for c in range(len(focal_lengths)):\n",
    "        ulens_transmittance[c,:,:] = torch.mul(torch.cos(exp_workaround) + torch.tensor(1j, dtype = torch.complex64) * torch.sin(exp_workaround), condition) # Exp seems to not work properly, so I'm using cos and sin instead #+ torch.mul(torch.tensor(1j), test)\n",
    "        ulens_transmittance = torch.mul((ulens_transmittance[c,:,:]), condition).unsqueeze(0)\n",
    "        \n",
    "    #ulens_transmittance = torch.from_numpy(ulens_transmittance)\n",
    "\n",
    "    # lenslet_centers_tensor is a tensor that has 1s where the lenslet centers are and 0s everywhere else\n",
    "    lenslet_centers_tensor = torch.zeros((len(calibration_img[0,:]), len(calibration_img[:,0])), dtype=torch.complex64).unsqueeze(0).unsqueeze(0).to(device) # [0,0,x,y]\n",
    "    \n",
    "    #lenslet_centers_tensor[0,0,lenslet_centers[:,0],lenslet_centers[:,1]] = 1\n",
    "\n",
    "    ulens_transmittance = ulens_transmittance.unsqueeze(0).to(device)# [0,focal length,x,y]\n",
    "    \n",
    "    for i in range(len(lenslet_centers[:,0])):\n",
    "        # Grab a kernel sized chunk of the lenslet centers tensor, but don't go out of bounds. Instead, pad with zeros\n",
    "        #lenslet_center_x = lenslet_distances_norm[i,0] + np.ceil((lenslet_centers_tensor.shape[2] +1) /2) # The center of the lenslet in the lenslet space\n",
    "        #lenslet_center_y = lenslet_distances_norm[i,1] + np.ceil((lenslet_centers_tensor.shape[3] +1) /2) # The center of the lenslet in the lenslet space\n",
    "        \n",
    "        lenslet_center_x = lenslet_centers[i,0] #+ np.ceil((lenslet_centers_tensor.shape[2] +1) /2) # The center of the lenslet in the lenslet space\n",
    "        lenslet_center_y = lenslet_centers[i,1] #+ np.ceil((lenslet_centers_tensor.shape[3] +1) /2) # The center of the lenslet in the lenslet space\n",
    "            \n",
    "        grab_x_start = int(lenslet_center_x - np.ceil((ulens_transmittance.shape[2] +1) /2))\n",
    "        grab_y_start = int(lenslet_center_y - np.ceil((ulens_transmittance.shape[3] +1) /2))\n",
    "        grab_x_end = int(lenslet_center_x + np.floor((ulens_transmittance.shape[2] -1) /2))\n",
    "        grab_y_end = int(lenslet_center_y + np.floor((ulens_transmittance.shape[3] -1) /2))\n",
    "        \n",
    "        pull_x_start = int(0)\n",
    "        pull_y_start = int(0)\n",
    "        pull_x_end = int(ulens_transmittance.shape[2])\n",
    "        pull_y_end = int(ulens_transmittance.shape[3])\n",
    "        \n",
    "        if grab_x_start < 0:\n",
    "            pull_x_start = int(abs(grab_x_start)+1)\n",
    "            grab_x_start = int(0)\n",
    "        if grab_y_start < 0:\n",
    "            pull_y_start = int(abs(grab_y_start)+1)\n",
    "            grab_y_start = int(0)\n",
    "        if grab_x_end > int(lenslet_centers_tensor.shape[2]):\n",
    "            grab_x_end = int(lenslet_centers_tensor.shape[2])\n",
    "            pull_x_end = int(grab_x_end - grab_x_start)\n",
    "        if grab_y_end > int(lenslet_centers_tensor.shape[3]):\n",
    "            grab_y_end = int(lenslet_centers_tensor.shape[3])\n",
    "            pull_y_end = int(grab_y_end - grab_y_start)\n",
    "        \n",
    "        lenslet_centers_tensor[:,:,grab_x_start:grab_x_end,grab_y_start:grab_y_end] = ulens_transmittance[:,:,pull_x_start:pull_x_end,pull_y_start:pull_y_end]\n",
    "\n",
    "    return lenslet_centers_tensor, ulens_transmittance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulens_transmit, single_lens_transmittance = transmittance(camera_params[1], circles_corrected, mask_img, fm, pixel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties that I do not know and I will just use the values in the code\n",
    "proportion = 3\n",
    "LU0 = 2500  # microns, physical length of the of sampled input at the NOP\n",
    "N_calcPSF = 7999  # Resolution of the point spread function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psfCalc(fobj, k, NA, calibration_img, pixel_pitch, wavelength, n, depths):\n",
    "    # Feed in depths as a list of depths\n",
    "    \n",
    "    device = \"cpu\"\n",
    "    \n",
    "    #if torch.cuda.is_available():\n",
    "    #    device = torch.device(\"cuda:0\")\n",
    "    #else:\n",
    "    #    device = torch.device(\"cpu\")\n",
    "    \n",
    "    sensor_spatial = [int(len(calibration_img[:,0]) * pixel_pitch /2 ), int(len(calibration_img[0,:]) * pixel_pitch /2 )]# sensor size (in micron) = pixel size (in micron/px) * sensor size (in px)\n",
    "    sensor_size = [int(len(calibration_img[:,0])), int(len(calibration_img[0,:]))] # sensor size in pixels\n",
    "    \n",
    "    # fobj = objective focal length\n",
    "    # k = wave number\n",
    "    # NA = objective numerical aperture\n",
    "    # sensor_size = size of the sensor in microns, calculated from the calibration image size and the pixel size, sensor size (in micron) = pixel size (in micron/px) * sensor size (in px)\n",
    "    # d = lenslet pitch\n",
    "    # n = refractive index\n",
    "    # n_step = number of steps in the z direction\n",
    "    \n",
    "    # phase delay suffered by the rays is the optical path difference (WHy are we calculating this?)\n",
    "    #if n != n_step:\n",
    "        #theta_half = theta / 2\n",
    "       # diff = (d / config[8]) * (n-n_step) * (1 + 2*n / n_step * np.sin(theta_half)^2 + 2*(n+n_step) * (n**2) / (n_step**3) * np.sin(theta_half)^4)\n",
    "    #else:\n",
    "       #diff = 0\n",
    "        \n",
    "    # Now we simulate the propagation of the rays to the sensor plane\n",
    "    \n",
    "    amp = 1000 # Normalized amplitude of the rays\n",
    "    mid = int((N_calcPSF+1)/2) # Where the delta function is located, N_calcPSF is always odd\n",
    "    NOP_x = torch.linspace(-LU0/2, LU0/2, N_calcPSF, dtype = torch.float32).to(device) # x coordinates of the NOP plane\n",
    "    NOP_y = NOP_x.clone() # y coordinates of the NOP plane, we assume the NOP is square\n",
    "    x, y = torch.meshgrid(NOP_x, NOP_y, indexing = 'ij') # Meshgrid of the NOP\n",
    "    \n",
    "    scale_factor = max(sensor_size)/ N_calcPSF # Scale factor to account for the difference in the size of the sensor and the size of the PSF\n",
    "\n",
    "    psf_sensor = torch.zeros(len(depths), sensor_size[0], sensor_size[1]).to(device).to(torch.complex64) # Initialize the PSF with the sensor size\n",
    "    \n",
    "    dobj = 2 * NA * fobj # Diameter of the objective\n",
    "    M_relay = f2 / f1 # Relay magnification\n",
    "    \n",
    "    def circ(x, y, r):\n",
    "        return (x**2 + y**2 < r**2).to(int)\n",
    "    \n",
    "    # We note that the PSF is shift-invariant, so we can calculate the PSF at the origin\n",
    "    for i in range(len(depths)):\n",
    "        if depths[i] == 0:\n",
    "            depths[i] = 1e-8 # To avoid division by 0\n",
    "        \n",
    "        r = torch.div(torch.sqrt(torch.pow(x,2) + torch.pow(y,2) + torch.pow(depths[i], 2)),n) # Distance from the origin to the sensor plane\n",
    "        \n",
    "        if depths[i] > 0:\n",
    "            r = -r # To propogate to the lens\n",
    "        \n",
    "        U0 = torch.mul(torch.div(amp * k * torch.tensor([-1j], dtype = torch.complex64, device=device),r),torch.exp(torch.mul(k*torch.tensor([1j], dtype = torch.complex64,device = device), r))) / (2 * torch.pi)\n",
    "\n",
    "        source_sample_rate = LU0 / len(U0) # Sampling rate of the input field\n",
    "        U1 = torch.mul(torch.fft.fftshift(torch.fft.fft2(torch.fft.ifftshift(U0))), source_sample_rate**2).to(dtype=torch.complex64) # Propogate to the sensor plane, with a scaling factor to account for the sampling\n",
    "        coeffU1 = torch.tensor([-1j], dtype = torch.complex64,device=device) * torch.exp(k * fobj * torch.tensor([1j], dtype = torch.complex64, device = device)) / wavelength / fobj\n",
    "        U1 = torch.mul(coeffU1, U1)\n",
    "        \n",
    "        LU1 = wavelength * fobj / source_sample_rate # Physical length of the sampled input field at the sensor plane\n",
    "        \n",
    "        U1 = torch.mul(U1, circ(x*LU1/LU0, y*LU1/LU0, dobj/2)) # Multiply the PSF by the circle mask\n",
    "        \n",
    "        cut = [round(sensor_spatial[0] * (N_calcPSF + 1) / (2 * (M_relay * LU1))), round(sensor_spatial[1] * (N_calcPSF + 1) / (2 * M_relay * LU1))]\n",
    "        \n",
    "        U1 = U1[mid-cut[0]:mid+cut[0], mid-cut[1]:mid+cut[1]].unsqueeze(0).unsqueeze(0) # Cut the PSF to the correct size\n",
    "        \n",
    "        U1_real_resize = transforms.Resize(size = sensor_size , interpolation=transforms.InterpolationMode.BICUBIC, antialias=False)(torch.real(U1)) # Resize the PSF to the sensor size\n",
    "        U1_imag_resize = transforms.Resize(size = sensor_size , interpolation=transforms.InterpolationMode.BICUBIC, antialias=False)(torch.imag(U1)) # Resize the PSF to the sensor size\n",
    "        U1 = torch.complex(U1_real_resize, U1_imag_resize)\n",
    "        del U1_real_resize, U1_imag_resize\n",
    "        \n",
    "        U1 = U1.squeeze(0).squeeze(0)\n",
    "        \n",
    "        # When PSF is smaller than the sensor, we need to index the sensor space to the correct location\n",
    "        if len(U1[:,0]) < sensor_size[0]:\n",
    "            push_x_start = 0\n",
    "            push_x_end = len(U1[:,0])\n",
    "            pull_x_start = int((sensor_size[0] - len(U1[:,0]))/2)\n",
    "            pull_x_end = int((sensor_size[0] + len(U1[:,0]))/2)\n",
    "        \n",
    "        if len(U1[0,:]) < sensor_size[1]:\n",
    "            push_y_start = 0\n",
    "            push_y_end = len(U1[0,:])\n",
    "            pull_y_start = int((sensor_size[1] - len(U1[0,:]))/2)\n",
    "            pull_y_end = int((sensor_size[1] + len(U1[0,:]))/2)\n",
    "        \n",
    "        # When the PSF is bigger than the sensor, we need to crop the psf\n",
    "        if len(U1[:,0]) >= sensor_size[0]:\n",
    "            push_x_start = int((len(U1[:,0])-sensor_size[0])/2)\n",
    "            push_x_end = int((len(U1[:,0])+sensor_size[0])/2)\n",
    "            pull_x_start = int(0)\n",
    "            pull_x_end = int(sensor_size[0])\n",
    "        \n",
    "        if len(U1[0,:]) >= sensor_size[1]:\n",
    "            push_y_start = int((len(U1[0,:])-sensor_size[1])/2)\n",
    "            push_y_end = int((len(U1[0,:])+sensor_size[1])/2)\n",
    "            pull_y_start = int(0)\n",
    "            pull_y_end = int(sensor_size[1])\n",
    "\n",
    "        psf_sensor[i, pull_x_start:pull_x_end, pull_y_start:pull_y_end] = U1[push_x_start:push_x_end, push_y_start:push_y_end]\n",
    "        #psf_sensor[i,:,:] = transforms.Resize(size = sensor_size, interpolation=transforms.InterpolationMode.BICUBIC, antialias=False)(psf)[0,0,:,:] # Resize the PSF to the sensor size\n",
    "        \n",
    "        del U0, r, cut\n",
    "            \n",
    "    # Shift the center of the PSF to the center of the center lenslet\n",
    "    #psf_sensor = torch.roll(psf_sensor, shifts= (-int(lenslet_centers[center_lenslet, 0] - (sensor_size[0]/2)), -int(lenslet_centers[center_lenslet, 1] - (sensor_size[1]/2))), dims = (2,1))\n",
    "        \n",
    "    return psf_sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = torch.linspace(-100, 100, 20) # Depths in microns, 10 microns is the increment between depths\n",
    "psfStack = psfCalc(fobj, camera_params[1], NA, mask_img, pixel_size, wavelength, refractive_index, depths) # CPU usage is at 100% when running this. GPU would be better.\n",
    "torch.save(psfStack, './models_DONOTCOMMIT/psfStack.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFPSF(psfStack, calibration_image, pixel_size, mla2sensor, wavelength, ulens_transmittance, depths, device, path, save_psf = False):\n",
    "    \n",
    "    # psfStack is in the format [depth, x, y]\n",
    "    \n",
    "    if device == \"cuda\":\n",
    "        print(torch.cuda.is_available())\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    elif device == \"cpu\":\n",
    "        device = torch.device(\"cpu\")\n",
    "    elif device == \"mps\":\n",
    "        print(\"MPS may have unforeseen consequences...\")\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    else:\n",
    "        print(\"Device not recognized, using CPU\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    ulens_transmittance = ulens_transmittance.to(device)\n",
    "\n",
    "    forward = np.empty( (len(calibration_image[:,0]), len(calibration_image[0,:]), len(psfStack[:,0,0]))).astype(np.complex64)\n",
    "    backward = np.empty( (len(calibration_image[0,:]), len(calibration_image[:,0]), len(depths))).astype(np.float32)\n",
    "    \n",
    "    Nx = len(psfStack[0,:,0])\n",
    "    Ny = len(psfStack[0,0,:])\n",
    "    k = 2 * torch.pi / wavelength\n",
    "    \n",
    "    du = torch.div(1, (Nx * pixel_size))\n",
    "    dv = torch.div(1, (Ny * pixel_size))\n",
    "    u = torch.concatenate((torch.arange(0, np.ceil(Nx/2)), torch.arange(np.ceil(-Nx/2), 0))).to(device) * du\n",
    "    v = torch.concatenate((torch.arange(0, np.ceil(Ny/2)), torch.arange(np.ceil(-Ny/2), 0))).to(device) * dv\n",
    "    \n",
    "    u = u.cpu().numpy().astype(complex) # Exp workaround; pytorch gives false values for the exp function\n",
    "    v = v.cpu().numpy().astype(complex) # Exp workaround; pytorch gives false values for the exp function\n",
    "    \n",
    "    H = np.exp(1j * mla2sensor * k * np.emath.sqrt(1 - (wavelength**2) * (np.power(np.tile(u.reshape(-1, 1),(1, len(v))), 2) + np.power(np.tile(v,(len(u),1)), 2)))) # Transfer function of the lenslet array, u and v are the spatial frequencies, v first, then u\n",
    "    #exp_workaround_1 = mla2sensor * k * torch.sqrt(1 - (wavelength**2) * (torch.pow(u.reshape(-1, 1).repeat(1, len(v)), 2) + torch.pow(v.repeat(len(u),1), 2)))\n",
    "    #H = torch.cos(exp_workaround_1) + torch.mul(torch.tensor(1j), torch.sin(exp_workaround_1)) # Transfer function of the lenslet array, u and v are the spatial frequencies, v first, then u\n",
    "    #H = torch.exp(torch.tensor(1j, dtype=torch.complex64, device=device) * mla2sensor * k * torch.sqrt((1 - (wavelength**2) * mla2sensor * k * (torch.pow(u.reshape(-1, 1).repeat(1, len(v)), 2) + torch.pow(v.repeat(len(u),1), 2))).to(torch.complex64))) # Transfer function of the lenslet array, u and v are the spatial frequencies, v first, then u\n",
    "    \n",
    "    for i in range(len(psfStack[:,0,0])):\n",
    "        psfMLA = torch.mul(psfStack[i,:,:].to(device), torch.permute(ulens_transmittance[0,0,:,:].to(device).squeeze(0), (1,0)).squeeze(0)).cpu().numpy().astype(complex) # Multiply the PSF by the transmittance function\n",
    "        #exp_workaround2 = torch.cos(torch.tensor(k * mla2sensor)) + torch.mul(torch.tensor(1j), torch.sin(torch.tensor(k * mla2sensor)))\n",
    "        forward[:,:,i] = np.abs(np.emath.power(np.exp(1j * mla2sensor * k) * np.fft.ifft2(np.multiply(np.fft.fft2(psfMLA),H)), 2))\n",
    "        #forward[:,:,i] = torch.abs(torch.pow(torch.exp(1j*  mla2sensor * k * torch.sqrt(1 - (wavelength**2) * (torch.pow(u.reshape(-1, 1).repeat(1, len(v)), 2) + torch.pow(v.repeat(len(u),1), 2)))) * (torch.fft.ifft2(torch.mul(torch.fft.fft2(psfMLA),H))) ,2))\n",
    "        #forward[:,:,i] = torch.abs(torch.pow(exp_workaround2 * (torch.fft.ifft2(torch.mul(torch.fft.fft2(psfMLA),H))) ,2))\n",
    "    \n",
    "    forward = torch.from_numpy(forward.astype(np.float32))\n",
    "    backward = forward.clone()\n",
    "    \n",
    "    # Side note\n",
    "    # 1. The backward model is the same as the forward model, so transpose results afterwards.\n",
    "    # 2. Scaling and normalizing should be done cleverly, as the floating point numbers become very small and creatte numerical instability (i.e. negative numbers, NaNs, etc.)\n",
    "    \n",
    "    return forward, backward, psfMLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"./models_DONOTCOMMIT/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_test, backward_test, h = LFPSF(psfStack[:,:,:], mask_img, pixel_size, mla2sensor, wavelength, ulens_transmit, depths, \"cuda\", save_path, True) # This would be a great place to use multiprocessing/multithreading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(forward_test, save_path + \"forward_test.pt\")\n",
    "torch.save(backward_test, save_path + \"backward_test.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fluids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

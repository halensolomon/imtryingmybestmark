{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLFM Forward and Backward Projector Generator\n",
    "__Requirements__\n",
    "- Dependencies\n",
    "    - OpenCV, Numpy, Torch, Matplotlib, gc\n",
    "- Required Information\n",
    "    - Camera related information\n",
    "    - A image of the lenslets (or a image that shows the outlines.)\n",
    "    \n",
    "__Warning__\n",
    "- The methods used in the following code may generate inaccruate results. Consider using experimentally measured PSFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Camera Information\n",
    "(In the future, this will be done by reading a .txt or a .csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up Specific Constants\n",
    "NA = 0.4\n",
    "fobj = 10000\n",
    "f1 = 1\n",
    "f2 = 1\n",
    "fm = np.array([47000])\n",
    "\n",
    "mla2sensor = 47000 # microns\n",
    "lenspitch = 2520 # Lens pitch in microns \n",
    "pixel_size = 3.54 # Also referred to as pixel pitch in microns/px\n",
    "refractive_index = 1 # Refractive index of the medium\n",
    "wavelength = 0.5530\n",
    "\n",
    "noLensHoriz = 3\n",
    "noLensVert = 3\n",
    "\n",
    "spacingPixels = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLFM_setCameraParams(config):\n",
    "    # Config should be an array with the following parameters:\n",
    "    # [NA, fobj, f1, f2, fm, mla2sensor, lenspitch, pixel_size, wavelength, refractive_index, noLensHoriz, noLensVert, spacingPixels, horizOffset, vertOffset, shiftRow, gridRot]\n",
    "    \n",
    "    objRad = config[0] * config[1] # Objective radius = NA * fobj\n",
    "    k = 2 * np.pi * config[9] / config[8] # k = 2 * pi * refractive_index / wavelength (wave number)\n",
    "    M = (config[4] * config[3]) / (config[2] * config[1]) # Magnification = fm * f2 / (f1 * fobj)\n",
    "    d_refract = 3.5e-3 # Index of Refraction (__Don't know wherer the number came from__)\n",
    "    fsRad = config[6] * config[3] / (2 * config[4]) # Field stop radius = lenspitch * f2 / (2 * fm)\n",
    "    fovRad = fsRad / config[2]\n",
    "    return [objRad, k, M, d_refract, fsRad, fovRad]\n",
    "\n",
    "# Example: camera_params = FLFM_setCameraParams(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolution(camera_params, depth_step):\n",
    "    # Find the number of pixels behind a lesnlet\n",
    "    lenslet_pixels = [len(perspectives[0,0,0,:]), len(perspectives[0,0,:,0])]\n",
    "    # Corresponding sensor resolution\n",
    "    sensor_res = pixel_size\n",
    "    object_res = [pixel_size/camera_params[2], pixel_size/camera_params[2], depth_step] # config[2] is the magnification\n",
    "    fovRadVox = (camera_params[5] / i for i in object_res)  # Field of view radius in voxels\n",
    "    return [lenslet_pixels, sensor_res, object_res, fovRadVox]\n",
    "\n",
    "# example: res = resolution(camera_params, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hough Transform for Circle Detection \n",
    "(Do not need to do everytime unless mask has changed for some ungodly reason.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img = cv.imread(r'./test_images/mask1.tif', cv.IMREAD_GRAYSCALE)\n",
    "min_radius = int(len(mask_img[0,:])/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Hough circle detection, rounded to the nearest integer/pixel\n",
    "circles = cv.HoughCircles(mask_img, cv.HOUGH_GRADIENT, 1.2, 1.5*min_radius, param1=70,param2=25, minRadius= min_radius,maxRadius=3*min_radius)\n",
    "circles = np.uint16(np.around(circles))\n",
    "circles = np.reshape(circles, (circles.shape[1], circles.shape[2]))\n",
    "\n",
    "# Find which one is the center circle\n",
    "circle_x_avg = np.mean(circles[:,0])\n",
    "circle_y_avg = np.mean(circles[:,1])\n",
    "circle_r_avg = np.mean(circles[:,2])\n",
    "\n",
    "distances = []\n",
    "theta = []\n",
    "\n",
    "for i in range(len(circles[:,0])):\n",
    "    x,y = circles[i,0]-circle_x_avg, circles[i,1]-circle_y_avg\n",
    "    distances.append(np.sqrt((circles[i,0]-circle_x_avg)**2 + (circles[i,1]-circle_y_avg)**2))\n",
    "    theta.append(np.arctan2(y,x))\n",
    "\n",
    "theta = np.delete(theta, np.argmin(distances)) # Remove the center circle\n",
    "distances = np.delete(distances, np.argmin(distances)) # Remove the center circle\n",
    "\n",
    "theta = np.sort(theta) # Sort the angles\n",
    "  \n",
    "circle_theta_avg = np.mean(theta) # Average angle between circles\n",
    "circle_theta_avg2 = (np.argmax(theta) - np.argmin(theta)) / (len(theta) - 1) #\n",
    "circle_dist_avg = np.mean(distances)\n",
    "\n",
    "circles_corrected = np.array([circle_x_avg, circle_y_avg, circle_r_avg])\n",
    "\n",
    "for i in range(len(theta)):\n",
    "    circles_corrected = np.vstack((circles_corrected, (circle_x_avg+circle_dist_avg*np.cos(theta[i]), circle_y_avg+circle_dist_avg*np.sin(theta[i]), circle_r_avg))) # new circle centers and radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_lenslet = int(0) # center circle index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenslet_distances_og = np.zeros((len(circles_corrected[:,0]), len(circles_corrected[:,0])))\n",
    "lenslet_angles = np.zeros((len(circles_corrected[:,0]), len(circles_corrected[:,0])))\n",
    "\n",
    "# Find the distances between the lenset centers\n",
    "for i in range(len(circles_corrected[:,0])):\n",
    "    for j in range(len(circles_corrected[:,0])):\n",
    "        lenslet_distances_og[i,j] = (np.sqrt((circles_corrected[i,0]-circles_corrected[j,0])**2 + (circles_corrected[i,1]-circles_corrected[j,1])**2))\n",
    "        lenslet_angles[i,j] = np.arctan2(circles_corrected[i,1]-circles_corrected[j,1], circles_corrected[i,0]-circles_corrected[j,0])\n",
    "\n",
    "# Grab the 2nd diagonal of the matrix\n",
    "lenslet_distances = np.diagonal(lenslet_distances_og, offset = 1)\n",
    "lenslet_angles = np.diagonal(lenslet_angles, offset = 1)\n",
    "lenslet_distance_avg = np.mean(lenslet_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenslet_circle_mask = np.zeros((int(2*circles_corrected[0,2]+1),int(2*circles_corrected[0,2]+1)))\n",
    "\n",
    "# Create a circular mask that has 0s outside the circle and 1s inside the circle\n",
    "for i in range(int(2*circles_corrected[0,2]+1)):\n",
    "    r = circles_corrected[0,2]\n",
    "    for j in range(int(2*circles_corrected[0,2]+1)):\n",
    "        \n",
    "        if np.sqrt((i-r)**2 + (j-r)**2) <= r: # Assuming the radius of the first circle is the same as the rest\n",
    "            lenslet_circle_mask[i,j] = 1\n",
    "        else:\n",
    "            lenslet_circle_mask[i,j] = 0\n",
    "\n",
    "mask_tensor = torch.from_numpy(lenslet_circle_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspectives = torch.zeros(int(len(frames)), int(len(circles_corrected[:,0])) , int(2*circles_corrected[0,2]+1), int(2*circles_corrected[0,2]+1)) # Making the different perspectives te \"channels\", also the frames are always odd numbers\n",
    "# The first dimension is the frame number, the second dimension is the lenslet number, the third and fourth dimensions are the x and y dimensions of the lenslet\n",
    "\n",
    "for i in range(len(frames)):\n",
    "    for j in range(len(circles_corrected[:,0])):\n",
    "        placeholder = torch.Tensor(frames[i][int(circles_corrected[j,1]-circles_corrected[j,2]):int(circles_corrected[j,1]+circles_corrected[j,2]), int(circles_corrected[j,0]-circles_corrected[j,2]):int(circles_corrected[j,0]+circles_corrected[j,2])]) # Don't know why x and y are switched\n",
    "        \n",
    "        if placeholder.shape == perspectives[0,0,:,:].shape:\n",
    "            placeholder[:,:] = torch.mul(placeholder, mask_tensor)\n",
    "            perspectives[i,j,:,:] = placeholder[:,:]\n",
    "            \n",
    "        else:\n",
    "            # If the circle is too close to the edge of the image, we need to pad it\n",
    "            placeholder_x_deficit = int(2*circles_corrected[j,2]+1) - placeholder.shape[0]\n",
    "            placeholder_y_deficit = int(2*circles_corrected[j,2]+1) - placeholder.shape[1]\n",
    "            \n",
    "            if placeholder_x_deficit > 0:\n",
    "                placeholder = torch.cat((placeholder, torch.zeros(placeholder_x_deficit, placeholder.shape[1])), 0)\n",
    "            if placeholder_y_deficit > 0:\n",
    "                placeholder = torch.cat((placeholder, torch.zeros(placeholder.shape[0], placeholder_y_deficit)), 1)\n",
    "            if placeholder_x_deficit < 0:\n",
    "                placeholder = torch.cat((placeholder, torch.zeros(placeholder_x_deficit, placeholder.shape[1])), 0)\n",
    "            if placeholder_y_deficit < 0:\n",
    "                placeholder = torch.cat((placeholder, torch.zeros(placeholder.shape[0], placeholder_y_deficit)), 1)\n",
    "                \n",
    "            placeholder[:,:] = torch.mul(placeholder, mask_tensor)\n",
    "            perspectives[i,j,:,:] = placeholder[:,:] # This is the same as the placeholder, but padded with zeros if the circle is too close to the edge of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(perspectives, './models_DONOTCOMMIT/perspectives.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fluids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

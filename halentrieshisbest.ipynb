{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from fft_conv_pytorch import fft_conv, FFTConv2d\n",
    "import torchvision.transforms.functional as TF\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import gc\n",
    "from PIL import Image as im\n",
    "#import napari as nap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hough Transform for Circle Detection \n",
    "(Do not need to do everytime unless mask has changed for some ungodly reason.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img = cv.imread(r'./test_images/mask1.tif', cv.IMREAD_GRAYSCALE)\n",
    "min_radius = int(len(mask_img[0,:])/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Hough circle detection, rounded to the nearest integer/pixel\n",
    "circles = cv.HoughCircles(mask_img, cv.HOUGH_GRADIENT, 1.2, 1.5*min_radius, param1=70,param2=25, minRadius= min_radius,maxRadius=3*min_radius)\n",
    "circles = np.uint16(np.around(circles))\n",
    "circles = np.reshape(circles, (circles.shape[1], circles.shape[2]))\n",
    "\n",
    "# Find which one is the center circle\n",
    "circle_x_avg = np.mean(circles[:,0])\n",
    "circle_y_avg = np.mean(circles[:,1])\n",
    "circle_r_avg = np.mean(circles[:,2])\n",
    "\n",
    "distances = []\n",
    "theta = []\n",
    "\n",
    "for i in range(len(circles[:,0])):\n",
    "    x,y = circles[i,0]-circle_x_avg, circles[i,1]-circle_y_avg\n",
    "    distances.append(np.sqrt((circles[i,0]-circle_x_avg)**2 + (circles[i,1]-circle_y_avg)**2))\n",
    "    theta.append(np.arctan2(y,x))\n",
    "\n",
    "theta = np.delete(theta, np.argmin(distances)) # Remove the center circle\n",
    "distances = np.delete(distances, np.argmin(distances)) # Remove the center circle\n",
    "\n",
    "theta = np.sort(theta) # Sort the angles\n",
    "  \n",
    "circle_theta_avg = np.mean(theta) # Average angle between circles\n",
    "circle_theta_avg2 = (np.argmax(theta) - np.argmin(theta)) / (len(theta) - 1) #\n",
    "circle_dist_avg = np.mean(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure2 = plt.figure()\n",
    "figure2.set_tight_layout(True)\n",
    "ax1, ax2, ax3 = figure2.subplots(1,3)\n",
    "ax1.imshow(img, cmap= 'gray')\n",
    "\n",
    "for i in circles:\n",
    "    # draw the outer circle\n",
    "    circle = patches.Circle((i[0],i[1]),i[2], fill = False, color = 'r')\n",
    "    ax2.add_patch(circle)\n",
    "    ax2.imshow(img)\n",
    "\n",
    "for i in range(len(theta)):\n",
    "    # draw the center circle\n",
    "    center = patches.Circle((circle_x_avg,circle_y_avg),circle_r_avg, fill = False, color = 'r')\n",
    "    # Draw the outer circles by multiplying the average angle by i\n",
    "    circle = patches.Circle((circle_x_avg+circle_dist_avg*np.cos(theta[i]),circle_y_avg+circle_dist_avg*np.sin(theta[i])),circle_r_avg, fill = False, color = 'r') # really good fit\n",
    "    ax3.add_patch(center)\n",
    "    ax3.add_patch(circle)\n",
    "    ax3.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circles_corrected = np.array([circle_x_avg, circle_y_avg, circle_r_avg])\n",
    "\n",
    "for i in range(len(theta)):\n",
    "    circles_corrected = np.vstack((circles_corrected, (circle_x_avg+circle_dist_avg*np.cos(theta[i]), circle_y_avg+circle_dist_avg*np.sin(theta[i]), circle_r_avg))) # new circle centers and radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display corrected circles\n",
    "mask_fit = plt.figure()\n",
    "ax1 = mask_fit.subplots(1,1)\n",
    "\n",
    "ax1.imshow(mask_img)\n",
    "\n",
    "for i in range(len(circles_corrected[:,0])):\n",
    "    # draw the outer circle\n",
    "    squares = patches.Rectangle((circles_corrected[i,0]-circles_corrected[i,2], circles_corrected[i,1]-circles_corrected[i,2]), 2*circles_corrected[i,2], 2*circles_corrected[i,2], fill = False, color = 'r')\n",
    "    circle = patches.Circle((circles_corrected[i,0],circles_corrected[i,1]),circles_corrected[i,2], fill = False, color = 'r')\n",
    "    ax1.add_patch(squares)\n",
    "    ax1.add_patch(circle)\n",
    "    \n",
    "    # Add the order of the circles in the center of each circle\n",
    "    ax1.text(circles_corrected[i,0], circles_corrected[i,1], str(i), color = 'r', horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "mask_fit.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the \"center\" lenslet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_lenslet = int(0) # center circle index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import frames for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the near future, auto-pulling frames from videos will be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = [r'./test_images/img_time1_1.tif', r'./test_images/img_time1_2.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = [r'./test_images/img_time1_1.tif', r'./test_images/img_time1_2.tif']\n",
    "frames = [] # List of frames\n",
    "for i in image_path:\n",
    "    imge = im.open(i)\n",
    "    frames.append(np.array(imge).astype(np.int16))\n",
    "\n",
    "# Check if the frames are all the same size\n",
    "if np.unique([frames[i].shape for i in range(len(frames))]).size > 2:\n",
    "    raise ValueError('Frames are not all the same size!')\n",
    "\n",
    "# Check if the frames are the same size as the mask\n",
    "if np.any(np.unique([frames[i].shape for i in range(len(frames))]) != mask_img.shape) == True:\n",
    "    raise ValueError('Frames are not the same size as the mask!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure4 = plt.figure()\n",
    "ax1 = figure4.subplots(1,1)\n",
    "\n",
    "for i in range(len(circles_corrected[:,0])):\n",
    "    # draw the outer circle\n",
    "    squares = patches.Rectangle((circles_corrected[i,0]-circles_corrected[i,2], circles_corrected[i,1]-circles_corrected[i,2]), 2*circles_corrected[i,2], 2*circles_corrected[i,2], fill = False, color = 'r')\n",
    "    circle = patches.Circle((circles_corrected[i,0],circles_corrected[i,1]),circles_corrected[i,2], fill = False, color = 'r')\n",
    "    ax1.add_patch(squares)\n",
    "    ax1.add_patch(circle)\n",
    "    # Add the order of the circles in the center of each circle\n",
    "    ax1.text(circles_corrected[i,0], circles_corrected[i,1], str(i), color = 'r', horizontalalignment='center', verticalalignment='center')\n",
    "    #plot the centers of the circles\n",
    "    ax1.scatter(int(circles_corrected[i,0]), int(circles_corrected[i,1]), color = 'b')\n",
    "    \n",
    "ax1.imshow(frames[0], cmap= 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenslet_distances_og = np.zeros((len(circles_corrected[:,0]), len(circles_corrected[:,0])))\n",
    "lenslet_angles = np.zeros((len(circles_corrected[:,0]), len(circles_corrected[:,0])))\n",
    "\n",
    "# Find the distances between the lenset centers\n",
    "for i in range(len(circles_corrected[:,0])):\n",
    "    for j in range(len(circles_corrected[:,0])):\n",
    "        lenslet_distances_og[i,j] = (np.sqrt((circles_corrected[i,0]-circles_corrected[j,0])**2 + (circles_corrected[i,1]-circles_corrected[j,1])**2))\n",
    "        lenslet_angles[i,j] = np.arctan2(circles_corrected[i,1]-circles_corrected[j,1], circles_corrected[i,0]-circles_corrected[j,0])\n",
    "\n",
    "# Grab the 2nd diagonal of the matrix\n",
    "lenslet_distances = np.diagonal(lenslet_distances_og, offset = 1)\n",
    "lenslet_angles = np.diagonal(lenslet_angles, offset = 1)\n",
    "lenslet_distance_avg = np.mean(lenslet_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenslet_circle_mask = np.zeros((int(2*circles_corrected[0,2]+1),int(2*circles_corrected[0,2]+1)))\n",
    "\n",
    "# Create a circular mask that has 0s outside the circle and 1s inside the circle\n",
    "for i in range(int(2*circles_corrected[0,2]+1)):\n",
    "    r = circles_corrected[0,2]\n",
    "    for j in range(int(2*circles_corrected[0,2]+1)):\n",
    "        \n",
    "        if np.sqrt((i-r)**2 + (j-r)**2) <= r: # Assuming the radius of the first circle is the same as the rest\n",
    "            lenslet_circle_mask[i,j] = 1\n",
    "        else:\n",
    "            lenslet_circle_mask[i,j] = 0\n",
    "\n",
    "mask_tensor = torch.from_numpy(lenslet_circle_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspectives = torch.zeros(int(len(frames)), int(len(circles_corrected[:,0])) , int(2*circles_corrected[0,2]+1), int(2*circles_corrected[0,2]+1)) # Making the different perspectives te \"channels\", also the frames are always odd numbers\n",
    "# The first dimension is the frame number, the second dimension is the lenslet number, the third and fourth dimensions are the x and y dimensions of the lenslet\n",
    "\n",
    "for i in range(len(frames)):\n",
    "    for j in range(len(circles_corrected[:,0])):\n",
    "        placeholder = torch.Tensor(frames[i][int(circles_corrected[j,1]-circles_corrected[j,2]):int(circles_corrected[j,1]+circles_corrected[j,2]), int(circles_corrected[j,0]-circles_corrected[j,2]):int(circles_corrected[j,0]+circles_corrected[j,2])]) # Don't know why x and y are switched\n",
    "        \n",
    "        if placeholder.shape == perspectives[0,0,:,:].shape:\n",
    "            placeholder[:,:] = torch.mul(placeholder, mask_tensor)\n",
    "            perspectives[i,j,:,:] = placeholder[:,:]\n",
    "            \n",
    "        else:\n",
    "            # If the circle is too close to the edge of the image, we need to pad it\n",
    "            placeholder_x_deficit = int(2*circles_corrected[j,2]+1) - placeholder.shape[0]\n",
    "            placeholder_y_deficit = int(2*circles_corrected[j,2]+1) - placeholder.shape[1]\n",
    "            \n",
    "            if placeholder_x_deficit > 0:\n",
    "                placeholder = torch.cat((placeholder, torch.zeros(placeholder_x_deficit, placeholder.shape[1])), 0)\n",
    "            if placeholder_y_deficit > 0:\n",
    "                placeholder = torch.cat((placeholder, torch.zeros(placeholder.shape[0], placeholder_y_deficit)), 1)\n",
    "            if placeholder_x_deficit < 0:\n",
    "                placeholder = torch.cat((placeholder, torch.zeros(placeholder_x_deficit, placeholder.shape[1])), 0)\n",
    "            if placeholder_y_deficit < 0:\n",
    "                placeholder = torch.cat((placeholder, torch.zeros(placeholder.shape[0], placeholder_y_deficit)), 1)\n",
    "                \n",
    "            placeholder[:,:] = torch.mul(placeholder, mask_tensor)\n",
    "            perspectives[i,j,:,:] = placeholder[:,:] # This is the same as the placeholder, but padded with zeros if the circle is too close to the edge of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(perspectives, './models_DONOTCOMMIT/perspectives.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the different perspectives\n",
    "figure4 = plt.figure()\n",
    "ax1,ax2 = figure4.subplots(1,2)\n",
    "\n",
    "ith= int(1)\n",
    "jth= int(0)\n",
    "\n",
    "ax1.imshow(perspectives[ith,jth,:,:], cmap= 'gray')\n",
    "ax2.imshow(frames[ith][int(circles_corrected[jth,1]-circles_corrected[jth,2]):int(circles_corrected[jth,1]+circles_corrected[jth,2]), int(circles_corrected[jth,0]-circles_corrected[jth,2]):int(circles_corrected[jth,0]+circles_corrected[jth,2])], cmap= 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frames are all loaded, time to calculate the forward and backward projectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera-related info\n",
    "\n",
    "Future: Allow .txt files to be imported and read instead.\n",
    "\n",
    "Current values grabbed from FLFMconfigGW.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up Specific Constants\n",
    "grid_Type = \"hex\"\n",
    "\n",
    "NA = 0.4\n",
    "fobj = 10000\n",
    "f1 = 1\n",
    "f2 = 1\n",
    "fm = np.array([47000])\n",
    "\n",
    "mla2sensor = 47000 # microns\n",
    "lenspitch = 2520 # Lens pitch in microns \n",
    "pixel_size = 3.54 # Also referred to as pixel pitch in microns/px\n",
    "refractive_index = 1 # Refractive index of the medium\n",
    "wavelength = 0.5530\n",
    "\n",
    "noLensHoriz = 3\n",
    "noLensVert = 3\n",
    "\n",
    "spacingPixels = 777\n",
    "horizOffset = 1269\n",
    "vertOffset = 690\n",
    "\n",
    "shiftRow = 0\n",
    "gridRot = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLFM_setCameraParams(config):\n",
    "    # Config should be an array with the following parameters:\n",
    "    # [NA, fobj, f1, f2, fm, mla2sensor, lenspitch, pixel_size, wavelength, refractive_index, noLensHoriz, noLensVert, spacingPixels, horizOffset, vertOffset, shiftRow, gridRot]\n",
    "    \n",
    "    objRad = config[0] * config[1] # Objective radius = NA * fobj\n",
    "    k = 2 * np.pi * config[9] / config[8] # k = 2 * pi * refractive_index / wavelength (wave number)\n",
    "    M = (config[4] * config[3]) / (config[2] * config[1]) # Magnification = fm * f2 / (f1 * fobj)\n",
    "    d_refract = 3.5e-3 # Index of Refraction (__Don't know wherer the number came from__)\n",
    "    fsRad = config[6] * config[3] / (2 * config[4]) # Field stop radius = lenspitch * f2 / (2 * fm)\n",
    "    fovRad = fsRad / config[2]\n",
    "    return [objRad, k, M, d_refract, fsRad, fovRad]\n",
    "\n",
    "# Example: camera_params = FLFM_setCameraParams(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolution(camera_params, depth_step):\n",
    "    # Find the number of pixels behind a lesnlet\n",
    "    lenslet_pixels = [len(perspectives[0,0,0,:]), len(perspectives[0,0,:,0])]\n",
    "    # Corresponding sensor resolution\n",
    "    sensor_res = pixel_size\n",
    "    object_res = [pixel_size/camera_params[2], pixel_size/camera_params[2], depth_step] # config[2] is the magnification\n",
    "    fovRadVox = (camera_params[5] / i for i in object_res)  # Field of view radius in voxels\n",
    "    return [lenslet_pixels, sensor_res, object_res, fovRadVox]\n",
    "\n",
    "# example: res = resolution(camera_params, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load-in camera-related info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_params = FLFM_setCameraParams([NA, fobj, f1, f2, fm, mla2sensor, lenspitch, pixel_size, wavelength, refractive_index, noLensHoriz, noLensVert, spacingPixels, horizOffset, vertOffset, shiftRow, gridRot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = resolution(camera_params, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmittance & PSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code originally written in MatLab by Stefanoiu et. al, ported and modified by me.\n",
    "\n",
    "> Resolution.yspace, and Resolution.xspace is the sensor spatial space, in microns.\n",
    "\n",
    "> This should be calculated as the pixel size * (# of pixels in x, # of pixels in y), assuming that each pixel is square.\n",
    "\n",
    "\n",
    "Implementation in pyFLFM (This code):\n",
    "> sensor_res * [-sensorsize/2, sensorsize/2], with # of steps between the two numbers being the # of pixels in each direction (i.e. sensor_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmittance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transmittance(wavenumber, lenslet_centers, calibration_img, focal_lengths, pixel_pitch):\n",
    "    # Defining the local lenslet space\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    lenslet_pixels = 2*round(lenslet_centers[0,2])\n",
    "    \n",
    "    lenslet_pitch = pixel_pitch * lenslet_pixels # Supposedly the lenslet pitch is 2x the radius of the lenslet\n",
    "    \n",
    "    NNum_half = (lenslet_pixels / 2) # Number of pixels in the numerator, assuming the lenslet is square\n",
    "    xML = pixel_pitch * torch.arange(start=-NNum_half+1, end=NNum_half-1, step = 1, dtype = torch.float16) # x coordinates of the lenslet space\n",
    "    yML = xML.clone() # y coordinates of the lenslet space in the same units as xML\n",
    "    \n",
    "    #ulens_transmittance = np.zeros((len(focal_lengths),len(xML),len(yML)), dtype = np.complex64) # [focal length, x, y]\n",
    "    ulens_transmittance = torch.zeros([len(focal_lengths),len(xML),len(yML)], dtype = torch.complex32) # [focal length, x, y]\n",
    "    # Indexing: [lenslet x, lenslet y, focal length]\n",
    "    # Lenslet centers is saved as [lens no, [x,y,r]]\n",
    "    # We already have the distances between the lenslets, so we need to find the correct index for the x norm and y norm\n",
    "\n",
    "    distance = (torch.pow(xML.tile((len(xML),1)),2) + torch.pow(yML.reshape(-1,1).tile((1,len(yML))),2))\n",
    "    #distance = distance.numpy()\n",
    "\n",
    "\n",
    "    condition = (distance < (lenslet_pitch/2)**2) # Condition for the lenslet transmittance, is 1 inside the lenslet and 0 outside the lenslet\n",
    "    #condition.dtype\n",
    "    condition = condition.to(torch.complex32)\n",
    "    distance = distance.to(torch.complex32)\n",
    "    #print(distance_squared)\n",
    "    \n",
    "    exp_workaround = (-0.5 * distance * wavenumber / focal_lengths[0]).to(torch.complex32)\n",
    "    mul_test = torch.mul(torch.tensor(1j)*torch.sin(exp_workaround) + torch.cos(exp_workaround), condition)\n",
    "    #print(torch.angle(torch.tensor(1j)*torch.sin(exp_workaround) + torch.cos(exp_workaround)))\n",
    "\n",
    "    #exp_workaround = np.multiply(-0.5j * wavenumber / focal_lengths[0] , distance).astype(np.complex32)\n",
    "    \n",
    "    for c in range(len(focal_lengths)):\n",
    "        ulens_transmittance[c,:,:] = torch.mul(torch.cos(exp_workaround) + torch.tensor(1j, dtype = torch.complex32) * torch.sin(exp_workaround), condition) # Exp seems to not work properly, so I'm using cos and sin instead #+ torch.mul(torch.tensor(1j), test)\n",
    "        ulens_transmittance = torch.mul((ulens_transmittance[c,:,:]), condition).unsqueeze(0)\n",
    "        \n",
    "    #ulens_transmittance = torch.from_numpy(ulens_transmittance)\n",
    "\n",
    "    # lenslet_centers_tensor is a tensor that has 1s where the lenslet centers are and 0s everywhere else\n",
    "    lenslet_centers_tensor = torch.zeros((len(calibration_img[0,:]), len(calibration_img[:,0])), dtype=torch.complex32).unsqueeze(0).unsqueeze(0).to(device) # [0,0,x,y]\n",
    "    \n",
    "    #lenslet_centers_tensor[0,0,lenslet_centers[:,0],lenslet_centers[:,1]] = 1\n",
    "\n",
    "    ulens_transmittance = ulens_transmittance.unsqueeze(0).to(device)# [0,focal length,x,y]\n",
    "    \n",
    "    for i in range(len(lenslet_centers[:,0])):\n",
    "        # Grab a kernel sized chunk of the lenslet centers tensor, but don't go out of bounds. Instead, pad with zeros\n",
    "        #lenslet_center_x = lenslet_distances_norm[i,0] + np.ceil((lenslet_centers_tensor.shape[2] +1) /2) # The center of the lenslet in the lenslet space\n",
    "        #lenslet_center_y = lenslet_distances_norm[i,1] + np.ceil((lenslet_centers_tensor.shape[3] +1) /2) # The center of the lenslet in the lenslet space\n",
    "        \n",
    "        lenslet_center_x = lenslet_centers[i,0] #+ np.ceil((lenslet_centers_tensor.shape[2] +1) /2) # The center of the lenslet in the lenslet space\n",
    "        lenslet_center_y = lenslet_centers[i,1] #+ np.ceil((lenslet_centers_tensor.shape[3] +1) /2) # The center of the lenslet in the lenslet space\n",
    "            \n",
    "        grab_x_start = int(lenslet_center_x - np.ceil((ulens_transmittance.shape[2] +1) /2))\n",
    "        grab_y_start = int(lenslet_center_y - np.ceil((ulens_transmittance.shape[3] +1) /2))\n",
    "        grab_x_end = int(lenslet_center_x + np.floor((ulens_transmittance.shape[2] -1) /2))\n",
    "        grab_y_end = int(lenslet_center_y + np.floor((ulens_transmittance.shape[3] -1) /2))\n",
    "        \n",
    "        pull_x_start = int(0)\n",
    "        pull_y_start = int(0)\n",
    "        pull_x_end = int(ulens_transmittance.shape[2])\n",
    "        pull_y_end = int(ulens_transmittance.shape[3])\n",
    "        \n",
    "        if grab_x_start < 0:\n",
    "            pull_x_start = int(abs(grab_x_start)+1)\n",
    "            grab_x_start = int(0)\n",
    "        if grab_y_start < 0:\n",
    "            pull_y_start = int(abs(grab_y_start)+1)\n",
    "            grab_y_start = int(0)\n",
    "        if grab_x_end > int(lenslet_centers_tensor.shape[2]):\n",
    "            grab_x_end = int(lenslet_centers_tensor.shape[2])\n",
    "            pull_x_end = int(grab_x_end - grab_x_start)\n",
    "        if grab_y_end > int(lenslet_centers_tensor.shape[3]):\n",
    "            grab_y_end = int(lenslet_centers_tensor.shape[3])\n",
    "            pull_y_end = int(grab_y_end - grab_y_start)\n",
    "        \n",
    "        lenslet_centers_tensor[:,:,grab_x_start:grab_x_end,grab_y_start:grab_y_end] = ulens_transmittance[:,:,pull_x_start:pull_x_end,pull_y_start:pull_y_end]\n",
    "\n",
    "    return lenslet_centers_tensor, ulens_transmittance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulens_transmit, single_lens_transmittance = transmittance(camera_params[1], circles_corrected, mask_img, fm, pixel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure5 = plt.figure()\n",
    "figure5.set_tight_layout(True)\n",
    "ax1, ax2 = figure5.subplots(1,2)\n",
    "ax1.imshow(torch.real(single_lens_transmittance[0,0,:,:]))\n",
    "ax2.imshow(torch.imag(ulens_transmit[0,0,:,:]))\n",
    "\n",
    "# note that the plot looks like it's been flipped upside down, but it's just because of the way the image is plotted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">resolution.yspace, resolution.xspace is the sensor spatial space! (defined as sensor_res * [-sensorsize/2, sensorsize/2] with steps = # of pixels in the direction (=sensor_size)\n",
    "\n",
    ">Nnum is number of pixels behind each lenslet\n",
    "\n",
    ">resolution.yMLspace, resolution.xMLspace is the MLA spatial space (defined as sensor_res * [-Nnum/2, Nnum/2], steps of 1\n",
    "\n",
    ">Sensor_size is calibration picture resolution in pixels\n",
    "\n",
    ">sensor_res is um/px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties that I do not know and I will just use the values in the code\n",
    "proportion = 3\n",
    "LU0 = 2500  # microns, physical length of the of sampled input at the NOP\n",
    "N_calcPSF = 7999  # Resolution of the point spread function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psfCalc(fobj, k, NA, calibration_img, pixel_pitch, wavelength, n, depths):\n",
    "    # Feed in depths as a list of depths\n",
    "    \n",
    "    device = \"cpu\"\n",
    "    \n",
    "    #if torch.cuda.is_available():\n",
    "    #    device = torch.device(\"cuda:0\")\n",
    "    #else:\n",
    "    #    device = torch.device(\"cpu\")\n",
    "    \n",
    "    sensor_spatial = [int(len(calibration_img[:,0]) * pixel_pitch /2 ), int(len(calibration_img[0,:]) * pixel_pitch /2 )]# sensor size (in micron) = pixel size (in micron/px) * sensor size (in px)\n",
    "    sensor_size = [int(len(calibration_img[:,0])), int(len(calibration_img[0,:]))] # sensor size in pixels\n",
    "    \n",
    "    # fobj = objective focal length\n",
    "    # k = wave number\n",
    "    # NA = objective numerical aperture\n",
    "    # sensor_size = size of the sensor in microns, calculated from the calibration image size and the pixel size, sensor size (in micron) = pixel size (in micron/px) * sensor size (in px)\n",
    "    # d = lenslet pitch\n",
    "    # n = refractive index\n",
    "    # n_step = number of steps in the z direction\n",
    "    \n",
    "    # phase delay suffered by the rays is the optical path difference (WHy are we calculating this?)\n",
    "    #if n != n_step:\n",
    "        #theta_half = theta / 2\n",
    "       # diff = (d / config[8]) * (n-n_step) * (1 + 2*n / n_step * np.sin(theta_half)^2 + 2*(n+n_step) * (n**2) / (n_step**3) * np.sin(theta_half)^4)\n",
    "    #else:\n",
    "       #diff = 0\n",
    "        \n",
    "    # Now we simulate the propagation of the rays to the sensor plane\n",
    "    \n",
    "    amp = 1000 # Normalized amplitude of the rays\n",
    "    mid = int((N_calcPSF+1)/2) # Where the delta function is located, N_calcPSF is always odd\n",
    "    NOP_x = torch.linspace(-LU0/2, LU0/2, N_calcPSF, dtype = torch.float16).to(device) # x coordinates of the NOP plane\n",
    "    NOP_y = NOP_x.clone() # y coordinates of the NOP plane, we assume the NOP is square\n",
    "    x, y = torch.meshgrid(NOP_x, NOP_y, indexing = 'ij') # Meshgrid of the NOP\n",
    "    \n",
    "    scale_factor = max(sensor_size)/ N_calcPSF # Scale factor to account for the difference in the size of the sensor and the size of the PSF\n",
    "\n",
    "    psf_sensor = torch.zeros(len(depths), sensor_size[0], sensor_size[1]).to(device).to(torch.complex32) # Initialize the PSF with the sensor size\n",
    "    \n",
    "    dobj = 2 * NA * fobj # Diameter of the objective\n",
    "    M_relay = f2 / f1 # Relay magnification\n",
    "    \n",
    "    def circ(x, y, r):\n",
    "        return (x**2 + y**2 < r**2).to(int)\n",
    "    \n",
    "    # We note that the PSF is shift-invariant, so we can calculate the PSF at the origin\n",
    "    for i in range(len(depths)):\n",
    "        if depths[i] == 0:\n",
    "            depths[i] = 1e-8 # To avoid division by 0\n",
    "        \n",
    "        r = torch.div(torch.sqrt(torch.pow(x,2) + torch.pow(y,2) + torch.pow(depths[i], 2)),n) # Distance from the origin to the sensor plane\n",
    "        \n",
    "        if depths[i] > 0:\n",
    "            r = -r # To propogate to the lens\n",
    "        \n",
    "        U0 = torch.mul(torch.div(amp * k * torch.tensor([-1j], dtype = torch.complex32, device=device),r),torch.exp(torch.mul(k*torch.tensor([1j], dtype = torch.complex32,device = device), r))) / (2 * torch.pi)\n",
    "\n",
    "        source_sample_rate = LU0 / len(U0) # Sampling rate of the input field\n",
    "        U1 = torch.mul(torch.fft.fftshift(torch.fft.fft2(torch.fft.ifftshift(U0))), source_sample_rate**2).to(dtype=torch.complex32) # Propogate to the sensor plane, with a scaling factor to account for the sampling\n",
    "        coeffU1 = torch.tensor([-1j], dtype = torch.complex32,device=device) * torch.exp(k * fobj * torch.tensor([1j], dtype = torch.complex32, device = device)) / wavelength / fobj\n",
    "        U1 = torch.mul(coeffU1, U1)\n",
    "        \n",
    "        LU1 = wavelength * fobj / source_sample_rate # Physical length of the sampled input field at the sensor plane\n",
    "        \n",
    "        U1 = torch.mul(U1, circ(x*LU1/LU0, y*LU1/LU0, dobj/2)) # Multiply the PSF by the circle mask\n",
    "        \n",
    "        cut = [round(sensor_spatial[0] * (N_calcPSF + 1) / (2 * (M_relay * LU1))), round(sensor_spatial[1] * (N_calcPSF + 1) / (2 * M_relay * LU1))]\n",
    "        \n",
    "        U1 = U1[mid-cut[0]:mid+cut[0], mid-cut[1]:mid+cut[1]].unsqueeze(0).unsqueeze(0) # Cut the PSF to the correct size\n",
    "        \n",
    "        U1_real_resize = transforms.Resize(size = sensor_size , interpolation=transforms.InterpolationMode.BICUBIC, antialias=False)(torch.real(U1)) # Resize the PSF to the sensor size\n",
    "        U1_imag_resize = transforms.Resize(size = sensor_size , interpolation=transforms.InterpolationMode.BICUBIC, antialias=False)(torch.imag(U1)) # Resize the PSF to the sensor size\n",
    "        U1 = torch.complex(U1_real_resize, U1_imag_resize)\n",
    "        del U1_real_resize, U1_imag_resize\n",
    "        \n",
    "        U1 = U1.squeeze(0).squeeze(0)\n",
    "        \n",
    "        # When PSF is smaller than the sensor, we need to index the sensor space to the correct location\n",
    "        if len(U1[:,0]) < sensor_size[0]:\n",
    "            push_x_start = 0\n",
    "            push_x_end = len(U1[:,0])\n",
    "            pull_x_start = int((sensor_size[0] - len(U1[:,0]))/2)\n",
    "            pull_x_end = int((sensor_size[0] + len(U1[:,0]))/2)\n",
    "        \n",
    "        if len(U1[0,:]) < sensor_size[1]:\n",
    "            push_y_start = 0\n",
    "            push_y_end = len(U1[0,:])\n",
    "            pull_y_start = int((sensor_size[1] - len(U1[0,:]))/2)\n",
    "            pull_y_end = int((sensor_size[1] + len(U1[0,:]))/2)\n",
    "        \n",
    "        # When the PSF is bigger than the sensor, we need to crop the psf\n",
    "        if len(U1[:,0]) >= sensor_size[0]:\n",
    "            push_x_start = int((len(U1[:,0])-sensor_size[0])/2)\n",
    "            push_x_end = int((len(U1[:,0])+sensor_size[0])/2)\n",
    "            pull_x_start = int(0)\n",
    "            pull_x_end = int(sensor_size[0])\n",
    "        \n",
    "        if len(U1[0,:]) >= sensor_size[1]:\n",
    "            push_y_start = int((len(U1[0,:])-sensor_size[1])/2)\n",
    "            push_y_end = int((len(U1[0,:])+sensor_size[1])/2)\n",
    "            pull_y_start = int(0)\n",
    "            pull_y_end = int(sensor_size[1])\n",
    "\n",
    "        psf_sensor[i, pull_x_start:pull_x_end, pull_y_start:pull_y_end] = U1[push_x_start:push_x_end, push_y_start:push_y_end]\n",
    "        #psf_sensor[i,:,:] = transforms.Resize(size = sensor_size, interpolation=transforms.InterpolationMode.BICUBIC, antialias=False)(psf)[0,0,:,:] # Resize the PSF to the sensor size\n",
    "        \n",
    "        del U0, r, cut\n",
    "            \n",
    "    # Shift the center of the PSF to the center of the center lenslet\n",
    "    #psf_sensor = torch.roll(psf_sensor, shifts= (-int(lenslet_centers[center_lenslet, 0] - (sensor_size[0]/2)), -int(lenslet_centers[center_lenslet, 1] - (sensor_size[1]/2))), dims = (2,1))\n",
    "        \n",
    "    return psf_sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = torch.linspace(-100, 100, 20) # Depths in microns, 10 microns is the increment between depths\n",
    "psfStack = psfCalc(fobj, camera_params[1], NA, mask_img, pixel_size, wavelength, refractive_index, depths) # CPU usage is at 100% when running this. GPU would be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the PSF\n",
    "figure5 = plt.figure()\n",
    "#figure5.set_tight_layout(True)\n",
    "# make a 3d plot of the PSF with the depths as the z-axis\n",
    "ax = figure5.add_subplot(111)\n",
    "ax.set_aspect(len(psfStack[0,0,:])/len(psfStack[0,:,0]))\n",
    "figure5.colorbar(ax.imshow(np.real(psfStack[0,:,:])))\n",
    "ax.imshow(np.imag(psfStack[6,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFPSF(psfStack, calibration_image, pixel_size, mla2sensor, wavelength, ulens_transmittance, depths, device, path, save_psf = False):\n",
    "    \n",
    "    # psfStack is in the format [depth, x, y]\n",
    "    \n",
    "    if device == \"cuda\":\n",
    "        print(torch.cuda.is_available())\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    elif device == \"cpu\":\n",
    "        device = torch.device(\"cpu\")\n",
    "    elif device == \"mps\":\n",
    "        print(\"MPS may have unforeseen consequences...\")\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    else:\n",
    "        print(\"Device not recognized, using CPU\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    ulens_transmittance = ulens_transmittance.to(device)\n",
    "\n",
    "    forward = np.empty( (len(calibration_image[:,0]), len(calibration_image[0,:]), len(psfStack[:,0,0]))).astype(np.complex32)\n",
    "    backward = np.empty( (len(calibration_image[0,:]), len(calibration_image[:,0]), len(depths))).astype(np.float16)\n",
    "    \n",
    "    Nx = len(psfStack[0,:,0])\n",
    "    Ny = len(psfStack[0,0,:])\n",
    "    k = 2 * torch.pi / wavelength\n",
    "    \n",
    "    du = torch.div(1, (Nx * pixel_size))\n",
    "    dv = torch.div(1, (Ny * pixel_size))\n",
    "    u = torch.concatenate((torch.arange(0, np.ceil(Nx/2)), torch.arange(np.ceil(-Nx/2), 0))).to(device) * du\n",
    "    v = torch.concatenate((torch.arange(0, np.ceil(Ny/2)), torch.arange(np.ceil(-Ny/2), 0))).to(device) * dv\n",
    "    \n",
    "    u = u.numpy().astype(complex) # Exp workaround; pytorch gives false values for the exp function\n",
    "    v = v.numpy().astype(complex) # Exp workaround; pytorch gives false values for the exp function\n",
    "    \n",
    "    H = np.exp(1j * mla2sensor * k * np.emath.sqrt(1 - (wavelength**2) * (np.power(np.tile(u.reshape(-1, 1),(1, len(v))), 2) + np.power(np.tile(v,(len(u),1)), 2)))) # Transfer function of the lenslet array, u and v are the spatial frequencies, v first, then u\n",
    "    #exp_workaround_1 = mla2sensor * k * torch.sqrt(1 - (wavelength**2) * (torch.pow(u.reshape(-1, 1).repeat(1, len(v)), 2) + torch.pow(v.repeat(len(u),1), 2)))\n",
    "    #H = torch.cos(exp_workaround_1) + torch.mul(torch.tensor(1j), torch.sin(exp_workaround_1)) # Transfer function of the lenslet array, u and v are the spatial frequencies, v first, then u\n",
    "    #H = torch.exp(torch.tensor(1j, dtype=torch.complex64, device=device) * mla2sensor * k * torch.sqrt((1 - (wavelength**2) * mla2sensor * k * (torch.pow(u.reshape(-1, 1).repeat(1, len(v)), 2) + torch.pow(v.repeat(len(u),1), 2))).to(torch.complex64))) # Transfer function of the lenslet array, u and v are the spatial frequencies, v first, then u\n",
    "    \n",
    "    for i in range(len(psfStack[:,0,0])):\n",
    "        psfMLA = torch.mul(psfStack[i,:,:], torch.permute(ulens_transmittance[0,0,:,:].squeeze(0), (1,0)).squeeze(0)).numpy().astype(complex) # Multiply the PSF by the transmittance function\n",
    "        #exp_workaround2 = torch.cos(torch.tensor(k * mla2sensor)) + torch.mul(torch.tensor(1j), torch.sin(torch.tensor(k * mla2sensor)))\n",
    "        forward[:,:,i] = np.emath.power(np.exp(1j * mla2sensor * k) * np.fft.ifft2(np.multiply(np.fft.fft2(psfMLA),H)), 2)\n",
    "        #forward[:,:,i] = torch.abs(torch.pow(torch.exp(1j*  mla2sensor * k * torch.sqrt(1 - (wavelength**2) * (torch.pow(u.reshape(-1, 1).repeat(1, len(v)), 2) + torch.pow(v.repeat(len(u),1), 2)))) * (torch.fft.ifft2(torch.mul(torch.fft.fft2(psfMLA),H))) ,2))\n",
    "        #forward[:,:,i] = torch.abs(torch.pow(exp_workaround2 * (torch.fft.ifft2(torch.mul(torch.fft.fft2(psfMLA),H))) ,2))\n",
    "    \n",
    "    forward = torch.from_numpy(np.abs(forward)).to(device)\n",
    "    \n",
    "    for i in range(len(psfStack[:,0,0])):\n",
    "        forward[:,:,i] = torch.div(forward[:,:,i], torch.sum(forward[:,:,i])) # Sum the PSF at each depth and normalize it\n",
    "    \n",
    "    for j in range(len(psfStack[:,0,0])):\n",
    "        backward[:,:,j] = forward[:,:,j].t() # Transpose the PSF\n",
    "    \n",
    "    # Save function currently disabled as .pt is over 4GB and cannot be saved.\n",
    "    \n",
    "    return forward, backward, psfMLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"./test_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_test, backward_test, h = LFPSF(psfStack[:,:,:], mask_img, pixel_size, mla2sensor, wavelength, ulens_transmit, depths, \"cpu\", save_path, True) # This would be a great place to use multiprocessing/multithreading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_maximum = torch.amax(forward_test[:,:,10:], (0,1,2))\n",
    "print(forward_maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_figures = plt.figure(figsize = (25,10))\n",
    "forward_figures.set_tight_layout(True)\n",
    "\n",
    "forward_maximum = torch.amax(forward_test[:,:,10:], (0,1,2)).item()\n",
    "\n",
    "forward_ax = forward_figures.subplots(2,5).flatten()\n",
    "\n",
    "for i in range(len(forward_ax)):\n",
    "    forward_ax[i].imshow(forward_test[:,:,i], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_skinny(psf, lenslet_info, depths):\n",
    "    return_tensor = torch.zeros((len(lenslet_info), len(depths), 2 * int(max(lenslet_info[:, 2])) + 1, 2 * int(max(lenslet_info[:, 2])) + 1), dtype=torch.float16)\n",
    "\n",
    "    for i in range(len(lenslet_info)):\n",
    "        for j in range(len(depths)):\n",
    "            x_start = max(0, int(lenslet_info[i, 0] - lenslet_info[i, 2]))\n",
    "            x_end = min(int(lenslet_info[i, 0] + lenslet_info[i, 2]), psf.shape[0])\n",
    "            y_start = max(0, int(lenslet_info[i, 1] - lenslet_info[i, 2]))\n",
    "            y_end = min(int(lenslet_info[i, 1] + lenslet_info[i, 2]), psf.shape[1])\n",
    "            \n",
    "            x_return_start = int(max(0, lenslet_info[i, 2] - lenslet_info[i, 0]))\n",
    "            x_return_end = int(min(2 * lenslet_info[i, 2]+1, lenslet_info[i, 2] + psf.shape[0] - lenslet_info[i, 0]+1))\n",
    "            y_return_start = int(max(0, lenslet_info[i, 2] - lenslet_info[i, 1]+1))\n",
    "            y_return_end = int(min(2 * lenslet_info[i, 2]+1, lenslet_info[i, 2] + psf.shape[1] - lenslet_info[i, 1]))\n",
    "\n",
    "            return_tensor[i, j, x_return_start:x_return_end, y_return_start:y_return_end] = psf[x_start:x_end, y_start:y_end, j]\n",
    "\n",
    "    return return_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_psf(path):\n",
    "    # Loads the PSF stack from a path\n",
    "    #path = r'/Users/halensolomon/Code/FLFM_local/testing/psf_stack.pt'\n",
    "    \n",
    "    # if the file type is .pt, then we can just load it\n",
    "    if path[-3:] == '.pt':\n",
    "        psf = torch.load(path)\n",
    "    \n",
    "    # if the path is actually a folder, then we need to load in all the files in the folder\n",
    "    elif os.path.isdir(path):\n",
    "        psf = torch.zeros(len(os.listdir(path)), len(Image.open(path + '/' + os.listdir(path)[0]).convert('L').getdata()), len(Image.open(path + '/' + os.listdir(path)[0]).convert('L').getdata()))\n",
    "        \n",
    "        for i in range(len(os.listdir(path))):\n",
    "            psf[i,:,:] = torch.from_numpy(np.array(Image.open(path + '/' + os.listdir(path)[i]).convert('L').getdata()).reshape(Image.open(path + '/' + os.listdir(path)[i]).convert('L').size)).to(torch.float16)\n",
    "    \n",
    "    return psf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolution and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def richardson_lucy(e_i, oringinal_image, f, b):\n",
    "    torch.set_device('')\n",
    "    pad = (f[0][0].shape[0] - 1)/2\n",
    "    pad = int(pad)\n",
    "    \n",
    "    kernel_size = f.shape[0]\n",
    "    func1 = torch.nn.Conv2d(1, 1, kernel_size=kernel_size, stride=1, padding = pad, device = 'mps')\n",
    "    func1.weight = f\n",
    "    denom = func1(e_i)\n",
    "    \n",
    "    kernel_size = b.shape[0]\n",
    "    func2 = torch.nn.Conv2d(1, 1, kernel_size=kernel_size, stride=1, padding = pad, device = 'mps')\n",
    "    func2.weight = b\n",
    "    factor = func2(oringinal_image/denom)\n",
    "    \n",
    "    return e_i * factor\n",
    "\n",
    "def psf_WB_filter(psf, alpha, beta, pixelSize, depth_step, butterworth_order):\n",
    "    # Assuming that there is only one peak in the lenslet\n",
    "    # Frames is the input frames, given as a \n",
    "\n",
    "    if len(psf.shape) == 3:\n",
    "        psf = psf.unsqueeze(0) # Add a dimension for the lenslets, since only one lenslet was given\n",
    "\n",
    "    # input PSF size and center\n",
    "    _, Sz, Sx, Sy = psf.shape\n",
    "    Scx = (Sx+1)/2;\n",
    "    Scy = (Sy+1)/2\n",
    "    Scz = (Sz+1)/2\n",
    "    Sox = round((Sx+1)/2)\n",
    "    Soy = round((Sy+1)/2)\n",
    "    Soz = round((Sz+1)/2)\n",
    "    \n",
    "    # Pixel size in Fourier domain\n",
    "    px = 1/Sx\n",
    "    py = 1/Sy\n",
    "    pz = 1/Sz\n",
    "    \n",
    "    # Remember that the psf is in the format of [lenslet, depth, x, y]\n",
    "    # Permute the PSF to the format of [lenslet, x, y, depth]\n",
    "    psf = torch.permute(psf, (0, 2, 3, 1)) # [lenslet, x, y, depth]\n",
    "    \n",
    "    PSF_bp = torch.empty(psf.shape)\n",
    "    \n",
    "    psf_flip = torch.flip(psf, (1,2,3))\n",
    "    OTF_flip = torch.fft.fftn(psf_flip, dim = (1,2,3))\n",
    "    OTF_abs = torch.fft.fftshift(torch.abs(OTF_flip), dim = (1,2,3))\n",
    "    M = torch.amax(OTF_abs, (1,2), keepdim = True) # find maximum value and position\n",
    "    OTF_abs_norm = torch.div(OTF_abs, M)\n",
    "    \n",
    "    # Create Wiener filter\n",
    "    OTF_flip_norm = OTF_flip/M\n",
    "    OTF_Wiener = torch.div(OTF_flip_norm,(torch.pow(torch.abs(OTF_flip_norm),2) + alpha))\n",
    "    \n",
    "    # Calculate Cut-off Gain for Wiener Filter\n",
    "    OTF_Wiener_abs = torch.fft.fftshift(torch.abs(OTF_Wiener))\n",
    "    \n",
    "    # tplane = abs(squeeze(OTF_Wiener_a   bs(:,:,Soz))); % central slice\n",
    "    tplane = torch.abs(OTF_Wiener_abs[:,:,Soz]) # central slice\n",
    "    tline, _ = torch.max(tplane, dim=0, keepdim=False) # Should return maximums along each row, call each depth\n",
    "    \n",
    "    w = np.power((np.tile(np.arange(0,Sx), (Sy,1)).T - Scx),2)+ np.power((np.tile(np.arange(0,Sy),(Sx,1)) - Scy),2)\n",
    "    w = np.broadcast_to(w[...,None],w.shape+(Sz,)) + np.power(np.tile(np.arange(0,Sz).reshape(1,1,Sz),(Sx,Sy,1)) - Scz, 2) # repeat Sz in the 3rd dimension\n",
    "    w = torch.from_numpy(w)\n",
    "            \n",
    "    if len(psf.shape) == 3:\n",
    "        psf = psf.unsqueeze(0) # Add a dimension for the lenslets, since only one lenslet was given\n",
    "    \n",
    "    PSF_bp = torch.empty(psf.shape)\n",
    "    mask = torch.empty(Sx,Sy,Sz)\n",
    "\n",
    "    # Loop through all the lenslets\n",
    "    for j in range(int(psf.shape[0])):\n",
    "        # Loop through all the depths\n",
    "        for i in range(int(psf.shape[3])):\n",
    "            psf_numpy = psf[j,:,:,i].numpy()\n",
    "            # Grab the x and y coordinates of the maximum value of the PSF\n",
    "            [x,y] = np.where(psf_numpy == np.max(psf_numpy))\n",
    "            \n",
    "            # Grab the x and y slices of the PSF that contain the maximum value\n",
    "            psf_x = psf_numpy[:,y]\n",
    "            psf_y = psf_numpy[x,:]\n",
    "            \n",
    "            # Find the indices that are near the half-maximum of the PSF\n",
    "            idx_x = (np.abs(psf_x - (psf_numpy[x,y]/2))).argmin()\n",
    "            idx_y = (np.abs(psf_y - (psf_numpy[x,y]/2))).argmin()\n",
    "            \n",
    "            # Set the resolution cutoff by setting the resolution to the FWHM\n",
    "            resx = np.abs(x - idx_x) * pixelSize\n",
    "            resy = np.abs(y - idx_y) * pixelSize\n",
    "            resz = depth_step # The MatLab code assumes that the resolution is the same in all directions\n",
    "            \n",
    "            # Frequency cutoff in terms of pixels\n",
    "            tx = 1/resx/px\n",
    "            ty = 1/resy/py\n",
    "            tz = 1/resz/pz\n",
    "            \n",
    "            # to1 = max(round(Scx -tx), 1); to2 = min(round(Scx+tx), Sx);\n",
    "            to1 = max(np.round(Scx - tx), 1)\n",
    "            to2 = min(np.round(Scx + tx), Sx)\n",
    "            \n",
    "            # beta_wienerx = (tline(to1) + tline(to2))/2; % OTF frequency intensity at cutoff:x\n",
    "            beta_wienerx = (tline[:,i][to1] + tline[:,i][to2])/2 # OTF frequency intensity at cutoff:x\n",
    "\n",
    "            ee = beta_wienerx/(beta**2) - 1\n",
    "            \n",
    "            mask[:,:,i] = torch.div(1, torch.sqrt(1 + torch.mul(ee,(torch.pow(w[:,:,i],butterworth_order))))) # w^n = (kx/kcx)^pn\n",
    "            mask[:,:,i] = torch.fft.ifftshift(mask[:,:,i]) # Butterworth Filter\n",
    "\n",
    "        # Create Wiener-Butteworth Filter\n",
    "        OTF_bp = torch.mul(mask,OTF_Wiener) # Final OTF_bp cutfoff gain: beta\n",
    "            \n",
    "        PSF_bp[j,:,:,:] = torch.fft.fftshift(torch.real(torch.fft.ifftn(OTF_bp)))# final OTF_bp cutfoff gain: beta\n",
    "        \n",
    "    return PSF_bp\n",
    "\n",
    "def rl_depths(lenslet_images, psf, PSF_bp, device, iterations = 10):\n",
    "    # all of the forward and backward projectors are slightly different, so I'm going to have to do them all separately\n",
    "    # I'm going to have to do the forward and backward projectors for each depth AND for each lenslet\n",
    "    \n",
    "    # Lenslet_images format: frames, lenslet, x, y\n",
    "    # PSF,PSF_BP format: lenslet, depths, x, y -> treat lenslet like the channels for a given depth\n",
    "    \n",
    "    # Input format will be [time, lenslets, x, y], so i could utilize the groups = in_channels in the torch.nn.conv2d function\n",
    "    \n",
    "    if type(lenslet_images) != 'torch.Tensor':\n",
    "        lenslet_images = torch.tensor(lenslet_images)\n",
    " \n",
    "    lenslet_images_wb = torch.empty([lenslet_images.shape[0], lenslet_images.shape[1], psf.shape[1], lenslet_images.shape[2], lenslet_images.shape[3]], dtype = torch.float16).to('cpu')# times, lenslets, depths, x, y\n",
    "\n",
    "    psf = psf.to(torch.float16).to(device)\n",
    "    PSF_bp = PSF_bp.to(torch.float16).to(device)\n",
    "    lenslet_images = lenslet_images.to(torch.float16).to(device)\n",
    "    \n",
    "    for k in range(len(lenslet_images[:,0,0,0])):\n",
    "        # Each time step\n",
    "        for j in range(iterations):\n",
    "            \n",
    "            original_image = lenslet_images[k,:,:,:].clone() # Store the original image\n",
    "            original_image = original_image.to('cpu') # Send the original image to the CPU, since division is faster on the CPU\n",
    "            \n",
    "            for i in range(len(psf[0,:,0,0])):\n",
    "                print('Now processing depth # ' + str(i) + ' in frame # ' + str(k) + ' with iteration ' + str(j+1) + ' out of ' + str(iterations))\n",
    "                # At a given depth, all lenslets must be convolved with its corresponding projector\n",
    "                # Lenslet_images should be in the format of [depth, lenslet, x, y]\n",
    "                # Forward projector required to calculate the denominator\n",
    "                forward_proj_size = psf.shape[0]\n",
    "                func1 = torch.nn.Conv2d(len(psf[:,0,0,0]), len(psf[:,0,0,0]), kernel_size=forward_proj_size, stride=1, padding = 'same', device = device, bias = False, groups = len(psf[:,0,0,0]))\n",
    "                func1.weight = torch.nn.parameter.Parameter(psf[:,i,:,:].unsqueeze(1)).to(device)\n",
    "                print(\"The shape of the lenslet image is: \" + str(lenslet_images[k,:,:,:].shape) + \" and the shape of the weights is: \" + str(func1.weight.shape))\n",
    "                print(\"Checkpoint 1\")\n",
    "                denom = func1(lenslet_images[k,:,:,:])\n",
    "                denom = denom.to('cpu')\n",
    "                \n",
    "                # Backward projector required to calculate the multiplication factor\n",
    "                backward_proj_size = PSF_bp[:,:,i].shape[0]\n",
    "                func2 = torch.nn.Conv2d(len(psf[:,0,0,0]), len(psf[:,0,0,0]), kernel_size=backward_proj_size, stride=1, padding = 'same', device = device, bias = False, groups = len(psf[:,0,0,0]))\n",
    "                func2.weight = torch.nn.parameter.Parameter(PSF_bp[:,i,:,:].unsqueeze(1)).to(device)\n",
    "                print(\"The shape of the lenslet image is: \" + str(lenslet_images[k,:,:,:].shape) + \" and the shape of the denominator is: \" + str(denom.shape))\n",
    "                print(\"The shape of the weights is: \" + str(func2.weight.shape))\n",
    "                print(\"Checkpoint 2\")\n",
    "                division_result = torch.div(original_image,denom).to(device)\n",
    "                factor = func2(division_result)\n",
    "                factor = factor.to('cpu')\n",
    "                \n",
    "                # Multiply the orignal image by the factor\n",
    "                print(\"Checkpoint 3\")\n",
    "                e_i = lenslet_images[k,:,:,:].to('cpu')\n",
    "                lenslet_images[k,:,:,:] = torch.mul(e_i, factor)\n",
    "                lenslet_images_wb[k,:,i,:,:] = lenslet_images[k,:,:,:] # Store the information\n",
    "                \n",
    "                print(\"Checkpoint 4\")\n",
    "        # Sum all of the \"channels\" together to get the final image\n",
    "        # do this when the interations are done\n",
    "        lenslet_images_wb[k,:,i,:,:] = torch.sum(lenslet_images_wb, dim = 1, keepdim = True)\n",
    "        \n",
    "    return lenslet_images_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl_depths_whole(frames, PSF, PSF_bp, device, iterations = 10, path = r\"./\", cpu_option = 'cpu'):\n",
    "    # Take the whole lenslet image & the whole PSFs and apply the Richardson-Lucy algorithm to it\n",
    "    # Frames should be in the format of [time, x, y]\n",
    "    # PSF should be in the format of [depths, x, y]\n",
    "    # Output should be in the format of [time, depth, x, y]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        if type(frames) != 'torch.Tensor':\n",
    "            frames = torch.tensor(frames)\n",
    "        \n",
    "        if frames.dtype != torch.float32:\n",
    "            frames = frames.to(torch.float32)\n",
    "        \n",
    "        for k in range(len(frames[:,0,0])):\n",
    "            # Each time step\n",
    "            for i in range(len(PSF[:,0,0])):\n",
    "                # Each depth step\n",
    "                # Using depths as the channels\n",
    "                \n",
    "                forward = PSF[i,:,:].clone().to(torch.float32).to(device)\n",
    "                backward = PSF_bp[i,:,:].clone().to(torch.float32).to(device)\n",
    "                \n",
    "                forward_proj_size = forward.shape # The size of the forward projector\n",
    "                # Depth is the channel\n",
    "                func1 = FFTConv2d(1, 1, kernel_size=forward_proj_size, \n",
    "                                        stride=1, padding = 'same', bias = False, groups = 1)\n",
    "                func1.weight = torch.nn.parameter.Parameter(forward.unsqueeze(0).unsqueeze(0)).to(device)\n",
    "                \n",
    "                backward_proj_size = backward.shape\n",
    "                func2 = FFTConv2d(1, 1, kernel_size=backward_proj_size, \n",
    "                                        stride=1, padding = 'same', bias = False, groups = 1)\n",
    "                func2.weight = torch.nn.parameter.Parameter(backward.unsqueeze(0).unsqueeze(0)).to(device)\n",
    "                \n",
    "                original_image = frames[k,:,:].to(torch.float16).clone().to(cpu_option) # Format: (x,y)\n",
    "                e_i = original_image.clone().to(device)\n",
    "                #print(original_image.shape)\n",
    "                \n",
    "                for j in range(iterations):\n",
    "                    print(str(j) + 'th iteration out of ' + str(iterations) + ' for frame ' + str(k) + ' out of ' + str(len(frames[:,0,0])) + ' for depth ' + str(i) + ' out of ' + str(len(PSF[:,0,0])))\n",
    "                    # Each iteration\n",
    "                    denom = func1(e_i.unsqueeze(0).unsqueeze(0)).squeeze(0).squeeze(0) # Input: (x,y), Output: (1,1,x,y).squeeze(0).squeeze(0) = (d,x,y)\n",
    "                    denom = denom.to(cpu_option)\n",
    "                    #print(denom.shape)\n",
    "                    \n",
    "                    division_result = torch.div(original_image,denom).to(device) # Inputs: (x,y), Output: (x,y)\n",
    "                    factor = func2(division_result.unsqueeze(0).unsqueeze(0)).squeeze(0).squeeze(0) # Inputs: (1,1,x,y), Output: (x,y)\n",
    "                    factor = factor.to(cpu_option)\n",
    "                    #print(factor.shape)\n",
    "                    \n",
    "                    e_i = torch.mul(original_image, factor).to(device) # Inputs: (x,y), Output: (x,y)\n",
    "                    del denom, division_result, factor\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                torch.save(e_i, path + str(k) + '_' + str(i) + '.pt')\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = [r'./Users/halensolomon/Code/FLFM_local/pyFLFM/test_images/img_time1_1.tif', r'./Users/halensolomon/Code/FLFM_local/pyFLFM/test_images/img_time1_2.tif']\n",
    "frames = [] # List of frames\n",
    "for i in image_path:\n",
    "    imge = im.open(i)\n",
    "    frames.append(np.array(imge).astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_test = steve_psf\n",
    "backward_test = forward_test.clone()\n",
    "backward_test = backward_test.transpose(2,1)\n",
    "frames = torch.tensor(np.array(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x284b09990>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(forward_test[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5120, 6400])\n",
      "torch.Size([11, 5120, 6400])\n"
     ]
    }
   ],
   "source": [
    "print(frames.shape)\n",
    "print(forward_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tw/r7vzypfs02q87460_njpb5wm0000gn/T/ipykernel_54798/902507895.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  frames = torch.tensor(frames)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th iteration out of 5 for frame 0 out of 2 for depth 0 out of 11\n",
      "1th iteration out of 5 for frame 0 out of 2 for depth 0 out of 11\n",
      "2th iteration out of 5 for frame 0 out of 2 for depth 0 out of 11\n",
      "3th iteration out of 5 for frame 0 out of 2 for depth 0 out of 11\n",
      "4th iteration out of 5 for frame 0 out of 2 for depth 0 out of 11\n",
      "0th iteration out of 5 for frame 0 out of 2 for depth 1 out of 11\n",
      "1th iteration out of 5 for frame 0 out of 2 for depth 1 out of 11\n",
      "2th iteration out of 5 for frame 0 out of 2 for depth 1 out of 11\n",
      "3th iteration out of 5 for frame 0 out of 2 for depth 1 out of 11\n",
      "4th iteration out of 5 for frame 0 out of 2 for depth 1 out of 11\n",
      "0th iteration out of 5 for frame 0 out of 2 for depth 2 out of 11\n",
      "1th iteration out of 5 for frame 0 out of 2 for depth 2 out of 11\n",
      "2th iteration out of 5 for frame 0 out of 2 for depth 2 out of 11\n",
      "3th iteration out of 5 for frame 0 out of 2 for depth 2 out of 11\n",
      "4th iteration out of 5 for frame 0 out of 2 for depth 2 out of 11\n",
      "0th iteration out of 5 for frame 0 out of 2 for depth 3 out of 11\n",
      "1th iteration out of 5 for frame 0 out of 2 for depth 3 out of 11\n",
      "2th iteration out of 5 for frame 0 out of 2 for depth 3 out of 11\n",
      "3th iteration out of 5 for frame 0 out of 2 for depth 3 out of 11\n",
      "4th iteration out of 5 for frame 0 out of 2 for depth 3 out of 11\n",
      "0th iteration out of 5 for frame 0 out of 2 for depth 4 out of 11\n",
      "1th iteration out of 5 for frame 0 out of 2 for depth 4 out of 11\n",
      "2th iteration out of 5 for frame 0 out of 2 for depth 4 out of 11\n",
      "3th iteration out of 5 for frame 0 out of 2 for depth 4 out of 11\n",
      "4th iteration out of 5 for frame 0 out of 2 for depth 4 out of 11\n",
      "0th iteration out of 5 for frame 0 out of 2 for depth 5 out of 11\n",
      "1th iteration out of 5 for frame 0 out of 2 for depth 5 out of 11\n",
      "2th iteration out of 5 for frame 0 out of 2 for depth 5 out of 11\n",
      "3th iteration out of 5 for frame 0 out of 2 for depth 5 out of 11\n",
      "4th iteration out of 5 for frame 0 out of 2 for depth 5 out of 11\n",
      "0th iteration out of 5 for frame 0 out of 2 for depth 6 out of 11\n",
      "1th iteration out of 5 for frame 0 out of 2 for depth 6 out of 11\n",
      "2th iteration out of 5 for frame 0 out of 2 for depth 6 out of 11\n",
      "3th iteration out of 5 for frame 0 out of 2 for depth 6 out of 11\n",
      "4th iteration out of 5 for frame 0 out of 2 for depth 6 out of 11\n",
      "0th iteration out of 5 for frame 0 out of 2 for depth 7 out of 11\n",
      "1th iteration out of 5 for frame 0 out of 2 for depth 7 out of 11\n",
      "2th iteration out of 5 for frame 0 out of 2 for depth 7 out of 11\n",
      "3th iteration out of 5 for frame 0 out of 2 for depth 7 out of 11\n",
      "4th iteration out of 5 for frame 0 out of 2 for depth 7 out of 11\n",
      "0th iteration out of 5 for frame 0 out of 2 for depth 8 out of 11\n",
      "1th iteration out of 5 for frame 0 out of 2 for depth 8 out of 11\n",
      "2th iteration out of 5 for frame 0 out of 2 for depth 8 out of 11\n",
      "3th iteration out of 5 for frame 0 out of 2 for depth 8 out of 11\n",
      "4th iteration out of 5 for frame 0 out of 2 for depth 8 out of 11\n",
      "0th iteration out of 5 for frame 0 out of 2 for depth 9 out of 11\n",
      "1th iteration out of 5 for frame 0 out of 2 for depth 9 out of 11\n",
      "2th iteration out of 5 for frame 0 out of 2 for depth 9 out of 11\n",
      "3th iteration out of 5 for frame 0 out of 2 for depth 9 out of 11\n",
      "4th iteration out of 5 for frame 0 out of 2 for depth 9 out of 11\n",
      "0th iteration out of 5 for frame 0 out of 2 for depth 10 out of 11\n",
      "1th iteration out of 5 for frame 0 out of 2 for depth 10 out of 11\n",
      "2th iteration out of 5 for frame 0 out of 2 for depth 10 out of 11\n",
      "3th iteration out of 5 for frame 0 out of 2 for depth 10 out of 11\n",
      "4th iteration out of 5 for frame 0 out of 2 for depth 10 out of 11\n",
      "0th iteration out of 5 for frame 1 out of 2 for depth 0 out of 11\n",
      "1th iteration out of 5 for frame 1 out of 2 for depth 0 out of 11\n",
      "2th iteration out of 5 for frame 1 out of 2 for depth 0 out of 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m frames_rl \u001b[38;5;241m=\u001b[39m \u001b[43mrl_depths_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackward_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./Users/halensolomon/Code/FLFM_local/testing/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 42\u001b[0m, in \u001b[0;36mrl_depths_whole\u001b[0;34m(frames, PSF, PSF_bp, device, iterations, path, cpu_option)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(j) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mth iteration out of \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(iterations) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for frame \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(k) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(frames[:,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for depth \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(PSF[:,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])))\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Each iteration\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m denom \u001b[38;5;241m=\u001b[39m \u001b[43mfunc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43me_i\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# Input: (x,y), Output: (1,1,x,y).squeeze(0).squeeze(0) = (d,x,y)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m denom \u001b[38;5;241m=\u001b[39m denom\u001b[38;5;241m.\u001b[39mto(cpu_option)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#print(denom.shape)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fluids/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fluids/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fluids/lib/python3.11/site-packages/fft_conv_pytorch/fft_conv.py:209\u001b[0m, in \u001b[0;36m_FFTConv.forward\u001b[0;34m(self, signal)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, signal):\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfft_conv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fluids/lib/python3.11/site-packages/fft_conv_pytorch/fft_conv.py:132\u001b[0m, in \u001b[0;36mfft_conv\u001b[0;34m(signal, kernel, bias, padding, padding_mode, stride, dilation, groups)\u001b[0m\n\u001b[1;32m    130\u001b[0m kernel_fr\u001b[38;5;241m.\u001b[39mimag \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    131\u001b[0m output_fr \u001b[38;5;241m=\u001b[39m complex_matmul(signal_fr, kernel_fr, groups\u001b[38;5;241m=\u001b[39mgroups)\n\u001b[0;32m--> 132\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mirfftn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_fr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Remove extra padded values\u001b[39;00m\n\u001b[1;32m    135\u001b[0m crop_slices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m+\u001b[39m [\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, (signal_size[i] \u001b[38;5;241m-\u001b[39m kernel\u001b[38;5;241m.\u001b[39msize(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), stride_[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, signal\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m    138\u001b[0m ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "frames_rl = rl_depths_whole(frames, forward_test, backward_test, \"mps\", 5, r\"./Users/halensolomon/Code/FLFM_local/testing/\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "# Cooking with gas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x286b7f550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d9c163c0574ab999adae2aa159329a",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=1280.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(torch.load(r\"./Users/halensolomon/Code/FLFM_local/testing/0_5.pt\").cpu().numpy(),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_psf(path):\n",
    "    # Find all images in a folder:\n",
    "    imgs = []\n",
    "    accepted_filetypes = ['tif', 'tiff', 'png', 'jpg', 'jpeg', 'bmp']\n",
    "    for f in os.listdir(path):\n",
    "        ext = os.path.splitext(f)[1][1:]\n",
    "        if ext.lower() not in accepted_filetypes:\n",
    "            continue\n",
    "        imgs.append(im.open(path+f))\n",
    "    \n",
    "    # Convert them into a tensor for pyTorch\n",
    "    tensor_imgs = torch.tensor(np.array(imgs).astype(np.float32))\n",
    "    del imgs\n",
    "    gc.collect()\n",
    "    \n",
    "    return tensor_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "steve_psf = img_to_psf(r\"./Volumes/BLACK_/step3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 5120, 6400])\n"
     ]
    }
   ],
   "source": [
    "print(steve_psf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fluids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
